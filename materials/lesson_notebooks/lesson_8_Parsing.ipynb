{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_8_Parsing",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson notebook 8 - Parsing\n",
        "\n",
        "\n",
        "\n",
        "### 1. NLTK Chart parser\n",
        "\n",
        "First we'll look at a chart parser from NLTK.  This parser is not pretrained.  It will operate by following the production rules in the grammar we provide.\n",
        "\n",
        "\n",
        "### 2. NLTK Shift Reduce parser\n",
        "\n",
        "Next we'll run the NLTK shift reduce parser.  Again, this parser is also not pre-trained so it is completely dependent on the grammar we provide.  Since we are providing a toy grammar and an ambiguous sentence we end up without a single tree as output.\n",
        "\n",
        "### 3. NLTK Probabilistic Chart parser\n",
        "\n",
        "Third, we'll look at a probabilistic chart parser from NLTK.  This parser is not pretrained.  It will operate by following the production rules in the grammar we provide and score the sentences.\n",
        "\n",
        "\n",
        "### 4. SpaCy language processing examples\n",
        "\n",
        "Finally we'll use SpaCy, a pretrained open source language processing pipeline.  It provides a platform for processing text in a number of ways without having to perform any fine-tuning.\n",
        "\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2022-summer-main/blob/master/materials/lesson_notebooks/lesson_8_Parsing.ipynb)"
      ],
      "metadata": {
        "id": "0L5LQ2xlw2I9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. NLTK set up\n",
        "\n",
        "Let's set up our environment to run the NLTK library.  It was created before the advent of neural NLP but provides a greaillustration of these approaches and allows you to experiment with them."
      ],
      "metadata": {
        "id": "Gfh-AqbIMtEk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f0PrW_vywtRY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import subprocess\n",
        "import sys\n",
        "import nltk\n",
        "from nltk import Nonterminal, nonterminals, Production, CFG, PCFG"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. NLTK Chart parser\n"
      ],
      "metadata": {
        "id": "u1pP4Rj-ne6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that a [chart parser](https://www.nltk.org/howto/parse.html) requires some way of prioritizing production rules.  This can be done with a context free grammar.  Here's an example of such a grammar that deals with the wonderfully ambiguous line \"I shot an elephant in my pajamas\".  The prepositional phrase \"in my pajamas\" can be attached to the verb  \"shot\" meaning I was wearing pajamas or attached to the non \"elephant\" meaning the elephant was wearing my pajamas. Both parses are equally valid."
      ],
      "metadata": {
        "id": "NdZgCmc3nmha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we define our context free grammar.  A real grammar for English wold be significantly larger."
      ],
      "metadata": {
        "id": "CxW2Tjtbpt0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
        " S -> NP VP\n",
        " PP -> P NP\n",
        " NP -> Det N | Det N PP | 'I'\n",
        " VP -> V NP | VP PP\n",
        " Det -> 'an' | 'my'\n",
        " N -> 'elephant' | 'pajamas'\n",
        " V -> 'shot'\n",
        " P -> 'in'\n",
        " \"\"\")"
      ],
      "metadata": {
        "id": "xUwtEnMfwzly"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can feed our grammar and sentence in to the chart parser and generate some parses."
      ],
      "metadata": {
        "id": "TOk_aA_Ap9pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
        "parser = nltk.ChartParser(groucho_grammar)\n",
        "for tree in parser.parse(sent):\n",
        "     tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dh69Ftswzop",
        "outputId": "0a8665cd-8764-4d8f-d30d-6f1cc47281a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     S                                       \n",
            "  ___|______________                          \n",
            " |                  VP                       \n",
            " |         _________|__________               \n",
            " |        VP                   PP            \n",
            " |    ____|___              ___|___           \n",
            " |   |        NP           |       NP        \n",
            " |   |     ___|_____       |    ___|_____     \n",
            " NP  V   Det        N      P  Det        N   \n",
            " |   |    |         |      |   |         |    \n",
            " I  shot  an     elephant  in  my     pajamas\n",
            "\n",
            "     S                                   \n",
            "  ___|__________                          \n",
            " |              VP                       \n",
            " |    __________|______                   \n",
            " |   |                 NP                \n",
            " |   |     ____________|___               \n",
            " |   |    |     |          PP            \n",
            " |   |    |     |       ___|___           \n",
            " |   |    |     |      |       NP        \n",
            " |   |    |     |      |    ___|_____     \n",
            " NP  V   Det    N      P  Det        N   \n",
            " |   |    |     |      |   |         |    \n",
            " I  shot  an elephant  in  my     pajamas\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the parser includes trees for both prepositional attachment possibilities because both parses are equally valid given our grammar."
      ],
      "metadata": {
        "id": "GCpUUCgwqLlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Shift Reduce Parser Example\n",
        "\n",
        "Let's try NLTK's simple shift reduce parser.  This is a parser that uses a grammar we provide and generates a constituency parse that corresponds to our grammar.  As such it can only work as well as the grammar we provide.  If you alter the input sentence to inpclude words not in the grammar you will generte an exception."
      ],
      "metadata": {
        "id": "nAkUoNcmOKWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shift reduce parser example\n",
        "from nltk.grammar import Nonterminal\n",
        "from nltk.parse.api import ParserI\n",
        "from nltk.tree import Tree"
      ],
      "metadata": {
        "id": "pL1d3ep_wzsA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's run the shift reduce parser.  The buffer is loaded with all of the words in our sentence.  On the left, before the square bracket is a letter **S** or **R**.  **S** means the parser picks the Shift command and move a token from the buffer to the stack.  **R** means it chooses the reduce command so swaps out a word for a label based on the grammar.  The parser runs until the buffer is empty."
      ],
      "metadata": {
        "id": "MeXjtkwps45O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = nltk.parse.ShiftReduceParser(groucho_grammar, trace=2)\n",
        "for p in parser.parse(sent):\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "RnO6Rr9awzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc96f50b-496f-436a-aa6d-3791307bdb42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 'I shot an elephant in my pajamas'\n",
            "    [ * I shot an elephant in my pajamas]\n",
            "  S [ 'I' * shot an elephant in my pajamas]\n",
            "  R [ NP * shot an elephant in my pajamas]\n",
            "  S [ NP 'shot' * an elephant in my pajamas]\n",
            "  R [ NP V * an elephant in my pajamas]\n",
            "  S [ NP V 'an' * elephant in my pajamas]\n",
            "  R [ NP V Det * elephant in my pajamas]\n",
            "  S [ NP V Det 'elephant' * in my pajamas]\n",
            "  R [ NP V Det N * in my pajamas]\n",
            "  R [ NP V NP * in my pajamas]\n",
            "  R [ NP VP * in my pajamas]\n",
            "  R [ S * in my pajamas]\n",
            "  S [ S 'in' * my pajamas]\n",
            "  R [ S P * my pajamas]\n",
            "  S [ S P 'my' * pajamas]\n",
            "  R [ S P Det * pajamas]\n",
            "  S [ S P Det 'pajamas' * ]\n",
            "  R [ S P Det N * ]\n",
            "  R [ S P NP * ]\n",
            "  R [ S PP * ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the shift reduce parser doesn't produce a single constituency parse with an S at the top of the tree."
      ],
      "metadata": {
        "id": "YNTSyqq_5aHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Probabilistic Chart Parser\n",
        "\n",
        "Here is a probabilistic chart parser where we define a grammar and associate a probability with each of the productions.  We can use this to generate a joint probability for each parse of the sentence.\n",
        "\n",
        "First, we define our grammar and associate probabilities with each production.  Note that the probabilities associated with the left hand rule **VP** add up to one.  There is a vey low probability associated with attaching a prepositional phrase (PP) to a verb phrase (VP)."
      ],
      "metadata": {
        "id": "ifm3qbtU5aD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.parse import pchart"
      ],
      "metadata": {
        "id": "_Oo3PACh57wD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toy_pcfg2 = PCFG.fromstring(\"\"\"\n",
        "     S    -> NP VP         [1.0]\n",
        "     VP   -> V NP          [.59]\n",
        "     VP   -> V             [.40]\n",
        "     VP   -> VP PP         [.01]\n",
        "     NP   -> Det N         [.41]\n",
        "     NP   -> Name          [.28]\n",
        "     NP   -> NP PP         [.31]\n",
        "     PP   -> P NP          [1.0]\n",
        "     V    -> 'saw'         [.21]\n",
        "     V    -> 'shot'         [.51]\n",
        "     V    -> 'ran'         [.28]\n",
        "     N    -> 'boy'         [.11]\n",
        "     N    -> 'pajamas'      [.12]\n",
        "     N    -> 'table'       [.13]\n",
        "     N    -> 'telescope'   [.14]\n",
        "     N    -> 'elephant'    [.5]\n",
        "     Name -> 'Jack'        [.32]\n",
        "     Name -> 'Bob'         [.28]\n",
        "     Name -> 'I'           [.40]\n",
        "     P    -> 'in'          [.30] \n",
        "     P    -> 'with'        [.41]\n",
        "     P    -> 'under'       [.29]\n",
        "     Det  -> 'the'         [.41]\n",
        "     Det  -> 'an'          [.31]\n",
        "     Det  -> 'my'          [.28]\n",
        "     \"\"\")"
      ],
      "metadata": {
        "id": "WnnCaeSU5ZQK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
        "grammar = toy_pcfg2\n",
        "parser = pchart.InsideChartParser(grammar)\n",
        "for t in parser.parse(sent):\n",
        "    print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC3FpzJD6gJe",
        "outputId": "40074396-b455-48a6-9013-49d26d4e3dc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Name I))\n",
            "  (VP\n",
            "    (V shot)\n",
            "    (NP\n",
            "      (NP (Det an) (N elephant))\n",
            "      (PP (P in) (NP (Det my) (N pajamas)))))) (p=2.74386e-06)\n",
            "(S\n",
            "  (NP (Name I))\n",
            "  (VP\n",
            "    (VP (V shot) (NP (Det an) (N elephant)))\n",
            "    (PP (P in) (NP (Det my) (N pajamas))))) (p=8.85116e-08)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. SpaCy for Language Processing\n",
        "\n",
        "Let's set up our environment to run the current version of [SpaCy](https://spacy.io) and feed it a small snippet of text to see what it can do.  \n",
        "\n",
        "SpaCy is an open source industrial strength NLP engine that can perform multiple functions out of the box. It strikes a good balance between speed of processing and accuracy of predictions.  It comes with a number of different language models trained on the [OntoNotes5](https://catalog.ldc.upenn.edu/LDC2013T19) data set.  This means that it is already trained to do part of speech tagging and dependency parsing.  It can also be trained to do classification and a number of other tasks in the standard NLP stack.  It is very fast.  It can be a handy way of analyzing some text for exploratory data analysis. Another use is annotating some text to then create a labelled training set that you use to train up your own model independent of spaCy.\n",
        "\n",
        "spaCy uses a combination of techniques including embeddings and convolutional neural nets to genearate the output we see. \n"
      ],
      "metadata": {
        "id": "L5NAuPNPOWp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emk0eFYbwzyz",
        "outputId": "82dabc7f-3c22-48b3-e3a4-116b3c8c8fe5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy-lookups-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_EnoqmUwz1b",
        "outputId": "c1d69bb8-c189-4bd5-9249-b5ec0cd8fea1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-lookups-data\n",
            "  Downloading spacy_lookups_data-1.0.3-py2.py3-none-any.whl (98.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 98.5 MB 96 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n",
            "Installing collected packages: spacy-lookups-data\n",
            "Successfully installed spacy-lookups-data-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "print(spacy.__version__)\n",
        "print(pd.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebg7KXskwz5G",
        "outputId": "8ca846f1-5a18-4448-bea7-8014c4729be8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3.1\n",
            "1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-trained Language Models for SpaCy\n",
        "\n",
        "SpaCy has also been pre-trained on multiple languages.  When using it you need to select and load a specific language model.\n",
        "\n",
        "Make sure you first download a language model then load it into SpaCy. We're selecting English via the large model which gives us access to embeddings.  There are many other options and other languages. \n",
        "\n",
        "Downloading the large model can take a couple of minutes if your network is slower."
      ],
      "metadata": {
        "id": "FU2Cb3JGQhZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QafhqNfxwz6v",
        "outputId": "d1fe19fd-e185-4fbf-c196-ecc517d12bd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 400.7 MB 6.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (21.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load an english model -- the large model includes word embeddings\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "6CSDp0B5wz_n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Natural Language Processing Pipeline\n",
        "When you invoke spaCy with some input text it generates a set of objects.  spaCy wants to process \"document\" like objects. This document can be one sentence or can be many sentences.  You provide the text and spaCy runs the nlp function which returns a Doc object.  That Doc object contains a list of Token objects each of which is associated with a set of annotations.  Many examples below are just about harvesting the labels associated with each token after the processing of the Document. "
      ],
      "metadata": {
        "id": "XZjidc5bR4fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u\"This is a sentence that we want to process.\")\n",
        "\n",
        "print(\"The first word is: \") \n",
        "doc[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uT-xcQihR31j",
        "outputId": "8c67f147-22b5-4aac-e706-4c6e7434b2b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first word is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Similarity Calculations\n",
        "\n",
        "SpaCy can perform a similarity calculation between two document objects.  The SpaCy model leverages the word embeddings to produce a vector to represent each document."
      ],
      "metadata": {
        "id": "cbrDkYtLSe5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We're taking advantage of the large model which uses embeddings \n",
        "#This means we can compute the similarity of two sentences and synonymous words have similar embeddings\n",
        "doc1 = nlp(\"How do I adopt a cat?\")\n",
        "doc2 = nlp(\"How do I get a pet?\")\n",
        "\n",
        "doc1.similarity(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJYaelyhSee2",
        "outputId": "b42bd4d0-8d5c-46bb-cec0-c59178ed26b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9604635674376736"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's confirm how this works by feeding in two very different sentences and seeing a low similarity score.\n",
        "doc3 = nlp(\"I need to withdraw money from the bank.\")\n",
        "doc4 = nlp(\"The F1 race was won by last year's world champion.\")\n",
        "\n",
        "doc3.similarity(doc4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u95U1QEETjOw",
        "outputId": "d07f87a1-0ae2-4905-ca04-c35b0bc7e09e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6786785482979246"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentence Boundary Detection\n",
        "\n",
        "Let's demonstrate some of the capabilities built in to the SpaCy language processing pipeline.  One problem we sometimes have to deal with is sentence boundayr detection.  We want to process a sequence of words as a unit like a sentence.  We might then want to feed individual sentences in to some SpaCy process.\n",
        "\n",
        "Let's see if we can convert these five lines of text into the three sentences they contain."
      ],
      "metadata": {
        "id": "Eom49P2IQ1KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence detection\n",
        "# Given an input block of text, identify where the sentences end.\n",
        "\n",
        "about_text = ('Sentence boundary detection is actually'\n",
        "              ' a pretty hard problem.  Great advances'\n",
        "              ' have been made in the U.S. in the'\n",
        "              ' past decade. New neural nets'\n",
        "              ' like a CNN can help improve results on this classification task.')\n",
        "about_doc = nlp(about_text)\n",
        "sentences = list(about_doc.sents)\n",
        "#len(sentences)\n",
        " \n",
        "#now print out the three sentences\n",
        "for sentence in sentences:\n",
        "    print (sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9T8tvXtw0Cp",
        "outputId": "ca8b50e4-5ea0-4aa3-b964-46808da20118"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence boundary detection is actually a pretty hard problem.\n",
            " Great advances have been made in the U.S. in the past decade.\n",
            "New neural nets like a CNN can help improve results on this classification task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part of Speech Tagging\n",
        "Part of speech tagging can be very valuable.  Tagging words can allow you to quickly distinguish \"things\" from \"actions\" or \"events.\" \n",
        "SpaCy has several different tags to display related to part of speech as shown below.  First, we'll just print out the tags.  Second we'll take the output and display it in a table using pandas."
      ],
      "metadata": {
        "id": "TkZ3iyqIZM8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#POS with unpretty print\n",
        "\n",
        "for token in about_doc:\n",
        "    print (token, token.tag_, token.pos_, spacy.explain(token.tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBnQls-xw0J4",
        "outputId": "0c0c861b-d8da-416b-ab8b-392da80252b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence NN NOUN noun, singular or mass\n",
            "boundary NN NOUN noun, singular or mass\n",
            "detection NN NOUN noun, singular or mass\n",
            "is VBZ AUX verb, 3rd person singular present\n",
            "actually RB ADV adverb\n",
            "a DT DET determiner\n",
            "pretty RB ADV adverb\n",
            "hard JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "problem NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "  _SP SPACE whitespace\n",
            "Great JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "advances NNS NOUN noun, plural\n",
            "have VBP AUX verb, non-3rd person singular present\n",
            "been VBN AUX verb, past participle\n",
            "made VBN VERB verb, past participle\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "the DT DET determiner\n",
            "U.S. NNP PROPN noun, proper singular\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "the DT DET determiner\n",
            "past JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "decade NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "New JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "neural JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "nets NNS NOUN noun, plural\n",
            "like IN ADP conjunction, subordinating or preposition\n",
            "a DT DET determiner\n",
            "CNN NNP PROPN noun, proper singular\n",
            "can MD AUX verb, modal auxiliary\n",
            "help VB VERB verb, base form\n",
            "improve VB VERB verb, base form\n",
            "results NNS NOUN noun, plural\n",
            "on IN ADP conjunction, subordinating or preposition\n",
            "this DT DET determiner\n",
            "classification NN NOUN noun, singular or mass\n",
            "task NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's process that input from the variable *about_doc* and show the results of POS tagging the three sentences it contains.  We'll take that output and display it in a table with columns for the word, it's POS tag, a higher level syntactic description, and an explanation for the model."
      ],
      "metadata": {
        "id": "qMPNJS2SZtnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#POS\n",
        "#capturing the output in a pandas dataframe makes it easier to view\n",
        "dpos = pd.DataFrame()\n",
        "dpos['text'] = [token.text for token in about_doc]\n",
        "dpos['tag'] = [token.tag_ for token in about_doc]\n",
        "dpos['pos'] = [token.pos_ for token in about_doc]\n",
        "dpos['explain'] = [spacy.explain(token.tag_) for token in about_doc]\n",
        "\n",
        "dpos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OM_SSSyK2I1v",
        "outputId": "154d299c-2b85-4b96-86a0-4e726cef3536"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              text  tag    pos  \\\n",
              "0         Sentence   NN   NOUN   \n",
              "1         boundary   NN   NOUN   \n",
              "2        detection   NN   NOUN   \n",
              "3               is  VBZ    AUX   \n",
              "4         actually   RB    ADV   \n",
              "5                a   DT    DET   \n",
              "6           pretty   RB    ADV   \n",
              "7             hard   JJ    ADJ   \n",
              "8          problem   NN   NOUN   \n",
              "9                .    .  PUNCT   \n",
              "10                  _SP  SPACE   \n",
              "11           Great   JJ    ADJ   \n",
              "12        advances  NNS   NOUN   \n",
              "13            have  VBP    AUX   \n",
              "14            been  VBN    AUX   \n",
              "15            made  VBN   VERB   \n",
              "16              in   IN    ADP   \n",
              "17             the   DT    DET   \n",
              "18            U.S.  NNP  PROPN   \n",
              "19              in   IN    ADP   \n",
              "20             the   DT    DET   \n",
              "21            past   JJ    ADJ   \n",
              "22          decade   NN   NOUN   \n",
              "23               .    .  PUNCT   \n",
              "24             New   JJ    ADJ   \n",
              "25          neural   JJ    ADJ   \n",
              "26            nets  NNS   NOUN   \n",
              "27            like   IN    ADP   \n",
              "28               a   DT    DET   \n",
              "29             CNN  NNP  PROPN   \n",
              "30             can   MD    AUX   \n",
              "31            help   VB   VERB   \n",
              "32         improve   VB   VERB   \n",
              "33         results  NNS   NOUN   \n",
              "34              on   IN    ADP   \n",
              "35            this   DT    DET   \n",
              "36  classification   NN   NOUN   \n",
              "37            task   NN   NOUN   \n",
              "38               .    .  PUNCT   \n",
              "\n",
              "                                              explain  \n",
              "0                              noun, singular or mass  \n",
              "1                              noun, singular or mass  \n",
              "2                              noun, singular or mass  \n",
              "3                   verb, 3rd person singular present  \n",
              "4                                              adverb  \n",
              "5                                          determiner  \n",
              "6                                              adverb  \n",
              "7   adjective (English), other noun-modifier (Chin...  \n",
              "8                              noun, singular or mass  \n",
              "9                   punctuation mark, sentence closer  \n",
              "10                                         whitespace  \n",
              "11  adjective (English), other noun-modifier (Chin...  \n",
              "12                                       noun, plural  \n",
              "13              verb, non-3rd person singular present  \n",
              "14                              verb, past participle  \n",
              "15                              verb, past participle  \n",
              "16          conjunction, subordinating or preposition  \n",
              "17                                         determiner  \n",
              "18                              noun, proper singular  \n",
              "19          conjunction, subordinating or preposition  \n",
              "20                                         determiner  \n",
              "21  adjective (English), other noun-modifier (Chin...  \n",
              "22                             noun, singular or mass  \n",
              "23                  punctuation mark, sentence closer  \n",
              "24  adjective (English), other noun-modifier (Chin...  \n",
              "25  adjective (English), other noun-modifier (Chin...  \n",
              "26                                       noun, plural  \n",
              "27          conjunction, subordinating or preposition  \n",
              "28                                         determiner  \n",
              "29                              noun, proper singular  \n",
              "30                              verb, modal auxiliary  \n",
              "31                                    verb, base form  \n",
              "32                                    verb, base form  \n",
              "33                                       noun, plural  \n",
              "34          conjunction, subordinating or preposition  \n",
              "35                                         determiner  \n",
              "36                             noun, singular or mass  \n",
              "37                             noun, singular or mass  \n",
              "38                  punctuation mark, sentence closer  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b026a90d-85e6-4269-9772-65d9fb7c303b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>explain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>boundary</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>detection</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, 3rd person singular present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>actually</td>\n",
              "      <td>RB</td>\n",
              "      <td>ADV</td>\n",
              "      <td>adverb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pretty</td>\n",
              "      <td>RB</td>\n",
              "      <td>ADV</td>\n",
              "      <td>adverb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hard</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>problem</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation mark, sentence closer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td>_SP</td>\n",
              "      <td>SPACE</td>\n",
              "      <td>whitespace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Great</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>advances</td>\n",
              "      <td>NNS</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, plural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, non-3rd person singular present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>been</td>\n",
              "      <td>VBN</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, past participle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>made</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb, past participle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>U.S.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>noun, proper singular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>past</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>decade</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation mark, sentence closer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>New</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>neural</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>nets</td>\n",
              "      <td>NNS</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, plural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>like</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>CNN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>noun, proper singular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>can</td>\n",
              "      <td>MD</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, modal auxiliary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>help</td>\n",
              "      <td>VB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb, base form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>improve</td>\n",
              "      <td>VB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb, base form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>results</td>\n",
              "      <td>NNS</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, plural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>on</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>this</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>classification</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>task</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation mark, sentence closer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b026a90d-85e6-4269-9772-65d9fb7c303b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b026a90d-85e6-4269-9772-65d9fb7c303b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b026a90d-85e6-4269-9772-65d9fb7c303b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dependency Parsing\n",
        "\n",
        "Now let's test SpaCy's ability to generate dependency parse trees. SpaCy has been pre-trained on a number of different tasks, like T5. Spacy performs multiple analyses simultaneously so we can walk over the list of input tokens and simply call up the labels assigned to each token.\n",
        "\n",
        "This approach can be difficult for a human to read.  Sometimes the data can be used for training other models or for exploratory data analysis."
      ],
      "metadata": {
        "id": "0ED3q7VvcCN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dependency parsing\n",
        "w266_text = 'Students are learning Natural Language Processing in the W266 class.'\n",
        "w266_doc = nlp(w266_text)\n",
        "for token in w266_doc:\n",
        "    print (token.text, token.tag_, token.head.text, token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPjVaYc2Iv7",
        "outputId": "76b63c62-b057-488a-ad64-4b98a6e80791"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Students NNS learning nsubj\n",
            "are VBP learning aux\n",
            "learning VBG learning ROOT\n",
            "Natural NNP Language compound\n",
            "Language NNP Processing compound\n",
            "Processing NNP learning dobj\n",
            "in IN Processing prep\n",
            "the DT class det\n",
            "W266 NNP class compound\n",
            "class NN in pobj\n",
            ". . learning punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets capture the output and put it into a pandas dataframe for easier consumption."
      ],
      "metadata": {
        "id": "9dFgdZoGmzSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#if you capture the tags in a dataframe you can then perform additional \n",
        "#operations like counting and filtering and searching\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['text'] = [token.text for token in w266_doc]\n",
        "df['lemma'] = [token.lemma_ for token in w266_doc]\n",
        "df['is_punctuation'] = [token.is_punct for token in w266_doc]\n",
        "df['is_space'] = [token.is_space for token in w266_doc]\n",
        "df['shape'] = [token.shape_ for token in w266_doc]\n",
        "df['part_of_speech'] = [token.pos_ for token in w266_doc]\n",
        "df['pos_tag'] = [token.tag_ for token in w266_doc]\n",
        "df['head'] = [token.head.text for token in w266_doc] \n",
        "df['dep'] = [token.dep_ for token in w266_doc]\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "IL_s-17f2IuC",
        "outputId": "f01fe24c-a56e-45f0-9b79-74768b24a966"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          text       lemma  is_punctuation  is_space  shape part_of_speech  \\\n",
              "0     Students     student           False     False  Xxxxx           NOUN   \n",
              "1          are          be           False     False    xxx            AUX   \n",
              "2     learning       learn           False     False   xxxx           VERB   \n",
              "3      Natural     Natural           False     False  Xxxxx          PROPN   \n",
              "4     Language    Language           False     False  Xxxxx          PROPN   \n",
              "5   Processing  Processing           False     False  Xxxxx          PROPN   \n",
              "6           in          in           False     False     xx            ADP   \n",
              "7          the         the           False     False    xxx            DET   \n",
              "8         W266        W266           False     False   Xddd          PROPN   \n",
              "9        class       class           False     False   xxxx           NOUN   \n",
              "10           .           .            True     False      .          PUNCT   \n",
              "\n",
              "   pos_tag        head       dep  \n",
              "0      NNS    learning     nsubj  \n",
              "1      VBP    learning       aux  \n",
              "2      VBG    learning      ROOT  \n",
              "3      NNP    Language  compound  \n",
              "4      NNP  Processing  compound  \n",
              "5      NNP    learning      dobj  \n",
              "6       IN  Processing      prep  \n",
              "7       DT       class       det  \n",
              "8      NNP       class  compound  \n",
              "9       NN          in      pobj  \n",
              "10       .    learning     punct  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa09b99c-4651-48a0-9a0b-2339818a699e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>is_punctuation</th>\n",
              "      <th>is_space</th>\n",
              "      <th>shape</th>\n",
              "      <th>part_of_speech</th>\n",
              "      <th>pos_tag</th>\n",
              "      <th>head</th>\n",
              "      <th>dep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Students</td>\n",
              "      <td>student</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>learning</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>are</td>\n",
              "      <td>be</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxx</td>\n",
              "      <td>AUX</td>\n",
              "      <td>VBP</td>\n",
              "      <td>learning</td>\n",
              "      <td>aux</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>learning</td>\n",
              "      <td>learn</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VBG</td>\n",
              "      <td>learning</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Natural</td>\n",
              "      <td>Natural</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Language</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Language</td>\n",
              "      <td>Language</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Processing</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Processing</td>\n",
              "      <td>Processing</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>learning</td>\n",
              "      <td>dobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xx</td>\n",
              "      <td>ADP</td>\n",
              "      <td>IN</td>\n",
              "      <td>Processing</td>\n",
              "      <td>prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxx</td>\n",
              "      <td>DET</td>\n",
              "      <td>DT</td>\n",
              "      <td>class</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>W266</td>\n",
              "      <td>W266</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xddd</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>class</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>class</td>\n",
              "      <td>class</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NN</td>\n",
              "      <td>in</td>\n",
              "      <td>pobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>.</td>\n",
              "      <td>learning</td>\n",
              "      <td>punct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa09b99c-4651-48a0-9a0b-2339818a699e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa09b99c-4651-48a0-9a0b-2339818a699e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa09b99c-4651-48a0-9a0b-2339818a699e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dependency tree is a list of arcs and labels.  These are shown in the final two columns.  The 'head' column indicates the word from which the incoming arc originates and the 'dep' column contains the label associated with that tag.\n"
      ],
      "metadata": {
        "id": "89zO-O0ZjeOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visulaize the dependency tree with the call to 'displacy.render' and then displaying the resulting HTML code."
      ],
      "metadata": {
        "id": "rfg4bwMxi_CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from IPython.core.display import HTML\n"
      ],
      "metadata": {
        "id": "9PtOkFt52Ig7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html = displacy.render(w266_doc, style=\"dep\")\n",
        "#print(html)"
      ],
      "metadata": {
        "id": "vAbQGRGz2IdB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(html)"
      ],
      "metadata": {
        "id": "zF6wuFoM2Iaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "8e1ea1f0-b34a-4cbe-d9ec-8764c7e46153"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6df42de1fa9542048b7d631745c63946-0\" class=\"displacy\" width=\"1800\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Students</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">are</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Natural</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Language</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Processing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">W266</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">class.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6df42de1fa9542048b7d631745c63946-0-8\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6df42de1fa9542048b7d631745c63946-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll look at other SpaCy capabilities in later classes."
      ],
      "metadata": {
        "id": "d6Gh1U-ynIbT"
      }
    }
  ]
}