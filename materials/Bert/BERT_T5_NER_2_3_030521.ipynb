{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uYhR7ySQdvI"
      },
      "source": [
        "<h1><center>A Simple Named Entity Recognition Model using  BERT  and Keras </center></h1>\n",
        "    \n",
        "<h2><center>    (And Another Simple One Using T5)</center></h2>\n",
        "<h4><center>Initially prepared for UC Berkeley MIDS - W266</center></h4>\n",
        "\n",
        "\n",
        "<h3><center>SUMMARY</center></h3>\n",
        "\n",
        "In this notebook we investigate how we can leverage **BERT** (see [\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"](https://arxiv.org/pdf/1810.04805.pdf), by Devlin/Chang/Lee/Toutanova, Google AI Language) for the problem of Named Entity Recognition (NER). Their paper actually contains the NER use case as a fine-tuning example, but we are not striving to replicate necessarily exactly their approach but build the model in the most approachable and 'naive' way, i.e. simply applying a straightforward model that follows intuitively the BERT mantra leveraging its context-based embeddings.\n",
        "\n",
        "\n",
        "We look at the effect of also fine-tuning BERT layers vs just adding and training classification layers on top of the BERT model and find that in this cursory and certainly incomplete study the re-training of BERT layers does offer some advantages. We also perform a test reducing the training data by 90% and find that the results are still quite decent, re-emphasizing BERT's usefulness in situations where the data set is on the small side. \n",
        "\n",
        "**Update:** In the appendix, we also recast the NER problem as a 'translation problem', allowing us to also get some practice with **T5** [\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"](https://arxiv.org/pdf/1910.10683.pdf) , by C. Raffel et al. (Note that one likely would expect less favorable results for the specific NER problem, but the introduction of T5 is the purpose, not the actual result.)\n",
        "\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2022-summer-main/blob/master/materials/Bert/BERT_T5_NER_2_3_030521.ipynb)\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "I. [Introduction & Approach](#ia)   \n",
        "1. [Introduction](#intro)  \n",
        "2. [Problem Definition & Metrics](#problem)  \n",
        "3. [Notebook Strategy](#strategy)  \n",
        "\n",
        "\n",
        "II. [Setup](#setup)   \n",
        "1. [Data](#data)  \n",
        "2. [BERT](#bert)  \n",
        "3. [Getting Started](#start)  \n",
        "\n",
        "\n",
        "III. [Data Preprocessing](#preprocess)   \n",
        "1. [BERT Tokenizer & BERT as a Black Box](#tokenizer)  \n",
        "2. [Input Generation](#extract)  \n",
        "3. [Initial Data Analysis](#analysis) \n",
        "4. [Baseline: Always picking 'Other'](#baseline) \n",
        "5. [Train/Test Split](#split)  \n",
        "\n",
        "IV. [The Model](#model)   \n",
        "1. [Custom Loss & Accuracy](#custom)  \n",
        "2. [BERT Layer](#bert_layer)  \n",
        "2. [Model Construction](#ner_model) \n",
        "\n",
        "\n",
        "V. [Model Runs/Experiments](#runs)   \n",
        "1. [With BERT-layer Fine-Tuning](#retrain)  \n",
        "2. [Predictions & Confusion Matrix](#confusion)  \n",
        "3. [Without BERT-Layer Fine-Tuning](#basic)  \n",
        "4. [A 90%-Reduced Training Set](#tiny)  \n",
        "\n",
        "\n",
        "VI. [Summary](#summary)  \n",
        "\n",
        "Appendix: [T5](#T5)  \n",
        "\n",
        "\n",
        "\n",
        "## I. Introduction & Approach <a id=\"ia\" />\n",
        "\n",
        "### I. Introduction & Strategy <a id=\"intro\" />\n",
        "\n",
        "BERT and other context-aware embedding frameworks like [ELMO](https://arxiv.org/abs/1802.05365), OpenAI's [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), and [XLNet](https://arxiv.org/pdf/1906.08237.pdf), etc.  -  provide extremely useful basis for many NLP tasks. A key reason why these frameworks are so useful is that they allow us to use the power of extensive pre-training that was done on a (set of) large corpus/era. \n",
        "\n",
        "More specifically, their ability to encode deep contextual relationships between words (and sentences or sentence segments) derived from a generic set of tasks provides us with the context-specific embeddings.  Depending on the task, we can then simply add a couple of classification layers with a modest number of weights to fine-tune the combined model to our very specific NLP task that may not have the luxury of a very large labeled data set.\n",
        "\n",
        "There are numerous and very good resources available on the web for various of these tasks (Movie Reviews, Sentiment  Analysis, etc,.). In this notebook, we want to consider the task of Named Entity Recognition, as it features a number of useful complexities that are good to discuss:\n",
        "\n",
        "* token-level vs. sentence-level BERT output, which seems to be less-often discussed \n",
        "* potential one-to-many split of word-to-token by the tokenizer (what are we going to do for the labels?) \n",
        "* potentially a need for custom loss and accuracy definitions\n",
        "\n",
        "Conceptually, we will follow the original BERT paper in its approach to NER:\n",
        "\n",
        "<img src=\"BERT_NER_Devlin_et_al.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "<center>Image Source: \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"</center>\n",
        "\n",
        "Each word will need to be tokenized. We will then, sentence-by-sentence, feed in the tokenized text into BERT, resulting in our case (we are using the BERT's base model) in a 768-dimensional output vector for each input token (and other tokens that BERT wants us to add). We then simply add a fully-connected hidden layer and finally a classification of suitable dimension that will take each token-output and make a decision on its NER label.  \n",
        "\n",
        "\n",
        "This is very intuitive. However, a few obvious questions arise that we want to look at in this notebook:\n",
        "\n",
        "1) How do we need to pre-process the data set to be suitable for BERT?   \n",
        "3) How can we build the model in Keras?   \n",
        "4) How can we incorporate custom loss functions and accuracy calculations?   \n",
        "5) What does fine-tuning mean? Is it just adding and training new layer(s), or do I re-train BERT layers as well?   \n",
        "6) Do I need to worry about customizing the optimizer?  \n",
        "\n",
        "These and other questions we hope to be able to shed some light on. The dataset we will be using is the \"**Annotated Corpus for Named Entity Recognition using GMB [Groningen Meaning Bank]**\", which is shared on [Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). It contains sentences with 1m+ words, conveniently annotated with POS and NER tags. \n",
        "\n",
        "### I.2. Problem Definition & Metrics <a id=\"problem\" />\n",
        "\n",
        "Our task will obviously be to properly identify the NER tags. There are potentially two things to consider when we want to define our success metrics: \n",
        "\n",
        "1) If we send the data sentence-by-sentence, we will need to apply padding to ensure consistent length. This will create 'new' labels that we will call 'nerPad'. Also, words can be split into multiple tokens, requiring us to add filler labels, which we will denote 'nerX'.  (There are multiple ways to address this, but this is what we are choosing here.)\n",
        "\n",
        "If we do that, should we look at accuracy over all tokens? Probably not. So our **first metric will be: accuracy for tokens which were part of the original text (and only the first token if a word is split)**.\n",
        "\n",
        "2) As we know from NER problems, most tokens will be 'Other'. So we may get already a pretty decent baseline result by always predicting 'Other'. In situations like that it may be useful to also look at **our second metric: the accuracy for all original tokens that are not 'Other'**.\n",
        "\n",
        "\n",
        "### I.3. Notebook Strategy <a id=\"strategy\" />\n",
        "\n",
        "The outline that we will follow in this notebook is this:\n",
        "\n",
        "**1) Process the text**\n",
        "* re-assemble words into sentences. (The corpus is of the form one-line-one-word, with sentence markers.)\n",
        "* tokenize the sentences with the BERT Tokenizer\n",
        "* create the input ids required for BERT:\n",
        "   * **sentence_ids** [the list of token ids for each sentence]\n",
        "   * **mask_ids** [the specification whether a specific token should be masked out (we mask out '[PAD]' tokens)]\n",
        "   * **sequence_ids** [used to denote whether a token is part of the first, second, or other segment in each input example. For us, this will always be '0'.]\n",
        "* prepare the labels  \n",
        "\n",
        "Some complications can include:\n",
        "- some words may not be in vocab\n",
        "- words can get split into multiple tokens. What are the labels?\n",
        "- Sentences do not all have the same length. Padding!\n",
        "- usual formatting details, like \"10,000\" and \"\"\" for quotes in this case.\n",
        "\n",
        "**2) Analyze and prepare the data**\n",
        "* Identify balance/imbalance situation\n",
        "* Estimate baseline accuracy defined by 'always picking the most common token'\n",
        "* Split into training and test set\n",
        "\n",
        "**3) Build the model**\n",
        "* Build BERT layer\n",
        "* Add classification layer(s)\n",
        "* Define custom loss functions and metrics\n",
        "\n",
        "**4) Run a few experiments**\n",
        "* Allow for re-training of a few BERT layers\n",
        "* Investigate the confusion matrix\n",
        "* Compare results with the model without re-training BERT layers\n",
        "* Test how good the results would be if you only at 10% of the training data (~4k sentences) \n",
        "\n",
        "**Appendix: Try the NER task witgh T5**\n",
        "* Re-phrase NER problem as a translation problem (maybe not natural... but why not?) \n",
        "* Create training/test data\n",
        "* Run a test  \n",
        "\n",
        "This notebook leverages BERT and T5 implementations from Hugging Face.  \n",
        "\n",
        "The notebook was run with **Tensorflow 2.3** and **Transformers 4.0.0**, leveraging one GPU with 4 GB of memory. (Note that I ran out of GPU memory a couple of times and restarted appropriately. But other than that with the given versions the notebook should execute end-to-end.)\n",
        "\n",
        "\n",
        "\n",
        "## II. Setup & Strategy\n",
        "\n",
        "### II.1. Data<a id=\"data\" />\n",
        "\n",
        "First, obtain the dataset (\"**Annotated Corpus for Named Entity Recognition using GMB [Groningen Meaning Bank]**\", which is shared on [Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). The ner_dataset.csv file is the relevant file.\n",
        "\n",
        "You'll need to download that file to your local machine and then copy it onto your Google drive.  The file is about 15 MB in size.\n",
        "Once you have uploaded it to your GDrive you can authenticate and then access it in this colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuN8niCiTCi3",
        "outputId": "36cc6402-8872-4829-ff94-20c1d02c7a16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll have to look at the directory structure of you GDrive and then modify the path below to get at the ner_dataset.csv file that you have uploaded.  This command will give you a file listing of the directory in the path."
      ],
      "metadata": {
        "id": "vxHaAha8O1RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/Colab\\ Notebooks"
      ],
      "metadata": {
        "id": "qxb4IRC4TE-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us take a quick peek at the contents of the file:"
      ],
      "metadata": {
        "id": "2EHUQlgLOiju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNImJXi0QdvT",
        "outputId": "2b990e90-374d-4bad-9aed-9e24ee77de02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",.,.,O\r\n",
            "Sentence: 47958,They,PRP,O\r\n",
            ",say,VBP,O\r\n",
            ",not,RB,O\r\n",
            ",all,DT,O\r\n",
            ",of,IN,O\r\n",
            ",the,DT,O\r\n",
            ",rockets,NNS,O\r\n",
            ",exploded,VBD,O\r\n",
            ",upon,IN,O\r\n",
            ",impact,NN,O\r\n",
            ",.,.,O\r\n",
            "Sentence: 47959,Indian,JJ,B-gpe\r\n",
            ",forces,NNS,O\r\n",
            ",said,VBD,O\r\n",
            ",they,PRP,O\r\n",
            ",responded,VBD,O\r\n",
            ",to,TO,O\r\n",
            ",the,DT,O\r\n",
            ",attack,NN,O\r\n"
          ]
        }
      ],
      "source": [
        "!tail -20 drive/MyDrive/Colab\\ Notebooks/ner_dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K6XwOJ9QdvW"
      },
      "source": [
        "We see the words line-by-line, the labels (POS and NER), and the sentence boundaries. Perfect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbewQwR-QdvX"
      },
      "source": [
        "### II.2. Environment & Imports:  <a id=\"bert\" />\n",
        "\n",
        "First off, here are the versions of key libraries that need to be installed. (Obviously, newer versions generally are expected to work, but these versions were used in the notebook.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC83QrSsQdvX",
        "outputId": "fb2aa053-5f31-41ce-fddd-70806f90770f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow==2.8.2+zzzcolab20220527125636\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.8.0\n",
            "tensorflow-gcs-config==2.8.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-io-gcs-filesystem==0.26.0\n",
            "tensorflow-metadata==1.8.0\n",
            "tensorflow-probability==0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep tensorflow\n",
        "!pip freeze | grep sentencepiece\n",
        "!pip freeze | grep transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpJOX1-lU4Ug",
        "outputId": "6febb930-f5b7-414d-b035-9931cc834901"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 31.6 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Jc245CebQdvY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "import io\n",
        "import re\n",
        "\n",
        "import pickle\n",
        "from csv import reader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import sentencepiece\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_NLGgtJRQdvY"
      },
      "outputs": [],
      "source": [
        "tf.get_logger().setLevel(\"ERROR\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKSO_sB7QdvZ"
      },
      "source": [
        "BERT and T5 are easily imported from **Hugging Face's transformer library** (https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel, etc.):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f-eWkqGVJ6O",
        "outputId": "6c6814de-9bf0-4028-b7f4-d0efbdb5482a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w4fyEEgFQdva"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertModel, T5Tokenizer, TFT5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alJeq7UeQdvb"
      },
      "source": [
        "(For now we will only work with the BERT components. More on T5 in the appendix.)\n",
        "\n",
        "So the two components we need are the **model** and the **tokenizer**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry-PpMgpQdvb"
      },
      "source": [
        "Define some key parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gBcXGppoQdvc"
      },
      "outputs": [],
      "source": [
        "#data_path = './'  # path to ner_dataset.csv file , from \n",
        "data_path = 'drive/MyDrive/Colab Notebooks/'\n",
        "\n",
        "now = datetime.now() # current\n",
        "\n",
        "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
        "\n",
        "    \n",
        "\n",
        "    y_true: Shape: (batch x (max_length) )\n",
        "\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "\n",
        "    \n",
        "\n",
        "    returns: accuracy\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    #get labels and predictions\n",
        "\n",
        "    \n",
        "\n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "\n",
        "\n",
        "# make sure that the paths are accessible within the notebook\n",
        "sys.path.insert(0,data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_spUvyFQdvc"
      },
      "source": [
        "Obviously, we will need to do quite a bit of pre-processing. BERT - as well as NER in general - requires us to process the text in a larger context, which suggests that we should send the data to BERT sentence-by-sentence. (An alternative would also be to just chunk up the text, irrespective of sentence boundaries.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLVr_SNLQdvd"
      },
      "source": [
        "## III. Data Preprocessing <a id=\"preprocess\" />\n",
        "\n",
        "### III.1 BERT Tokenizer & BERT as a Black Box<a id=\"tokenizer\" />\n",
        "\n",
        "We need to define the tokenizer. BERT has its own and that is the one that should be used. As it is specific to the (pre-trained) model, we need to specify it. For obvious reasons we will use the 'cased'  model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "764c218231324ecfa94677e392a9411a",
            "59b7629edba64b03bd56b8c913d69939",
            "a5c46d2313ce4e1398bb63987ec825fb",
            "d1c0db0deccc4aa49bfea48ddbc4d894",
            "631572ea28524a7fad5de795081a83a9",
            "877841b5b2a74a20851dff467b273a5c",
            "19f7165ed7cb4f32a2fa179f838603a5",
            "e5302e1f680d4681922dcf1450da0c88",
            "9fee95b7865144a5815e1cab1fb5d78e",
            "71090841b24a4007ba20b9c3c3445970",
            "6feb9d69a6d542dca9aa4abd48fcfe0e",
            "13a9d59aa6ae4958a190214ff60b851d",
            "64f16e2323214a6099a29651939c9a3f",
            "321cbfaf8f1a47e99f2f3809f17221b0",
            "c1d63282168a4319973e7ede17650700",
            "e91ca6e9c9d8491b8365660ca4ff1b05",
            "1073082c5b3447d7b748cbc11e913b64",
            "fca76ca76f40487bbceb0e0e390a7a46",
            "7c939112d05f459fac9f37dd4977457b",
            "e3930e1bc6a14c989c0be7d38944331b",
            "680b36070820443487c5eb089634ab80",
            "990fcbeaf5654eaf991c6371ec55b9bf",
            "b46891c58a684293b13a71beb1e709dd",
            "d87efb493cfe434da681ad61ae0f5ed4",
            "6c9a630a1ed14b0cb4a4ca3de1216b34",
            "7435b402084042d395611ca4e70326e3",
            "806be634a1e84792915986f8bda67b62",
            "68c6f0f87dcc403588ad5c2d86cf4937",
            "1fde0878b74b421ca5090b76adc4aa83",
            "12cd825ea3fc460796e7c8c05c85a1de",
            "9b8a4875b6004b1bafc68826b62075c0",
            "5d2557e751034ee49a5d53f6ea635348",
            "11714a114f5b49e2a01e2c03c081510f"
          ]
        },
        "id": "u3nX1VO8Qdvd",
        "outputId": "8ba3c614-9159-494e-abfb-bbb132bc15c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "764c218231324ecfa94677e392a9411a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13a9d59aa6ae4958a190214ff60b851d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b46891c58a684293b13a71beb1e709dd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2sdzMC6Qdve"
      },
      "source": [
        "Let's play with the tokenizer. You will see that the tokenizer occasionally splits one word into multiple tokens. Why is that the case? Because the approach of using word pieces reduces the vocabulary size and/or number of unknown words.\n",
        "\n",
        "Here is one example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjTNBzpKQdve",
        "outputId": "a9f57973-209c-4f52-812a-e6e71b1ce02e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5mhU3ttQdvf",
        "outputId": "234b8184-fab1-4436-da47-9b5575480bcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'sentence',\n",
              " 'is',\n",
              " 'simple',\n",
              " 'and',\n",
              " 'uses',\n",
              " 'a',\n",
              " 'nice',\n",
              " 'data',\n",
              " '##set']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tokenizer.tokenize('This sentence is simple and uses a nice dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNtBT6w2Qdvf",
        "outputId": "d7a1f4ad-6317-4a20-a28e-6de280efc135"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 1142, 1110, 3123, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer.encode('this is easy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsFUxX8zQdvf"
      },
      "source": [
        "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB6_ImwZQdvg",
        "outputId": "e1df4af2-1e8a-48ff-d48a-9a302ac2927d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 1142, 1110, 3123, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tokenizer.convert_tokens_to_ids([\n",
        "    '[CLS]', 'this', 'is', 'easy', '[SEP]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpe5rK0oQdvg",
        "outputId": "6950d147-6582-4b3f-f736-ea2b0d497a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['people']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens([1234])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azuZONyXQdvg"
      },
      "source": [
        "Good. Now we are ready to use it for our text. \n",
        "\n",
        "But before we generate the model input data, let us first highlight also the BERT basics.\n",
        "\n",
        "We start by defining a BERT model that is created from one of the pre-trained models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "563cd6e39b654075ae9ebd8924071786",
            "09ca6b2f20e2434bb984b1231e229d3d",
            "2510857b66f0425ba78b8e4574b1f841",
            "615271962cbf4f979a4226647b5d5e9f",
            "d560949597b54eaca5ccf54ef1471994",
            "bf81c6d89e004f4da12b23c52ad2c2be",
            "78426cfe20e24df288bed67ad48e14a5",
            "f7a80d84aa694ce28510254bdc2288b0",
            "de58e65b6e704c6abd5461914b4036af",
            "841daef38713493ba32fb0aa312832c3",
            "525e38dce0c44433b01df3a9e1da922d"
          ]
        },
        "id": "tZtUrXieQdvh",
        "outputId": "614bc58f-9c3c-417d-e60f-60d751db264c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "563cd6e39b654075ae9ebd8924071786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f8744930510>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "bert = TFBertModel.from_pretrained('bert-base-cased')\n",
        "bert.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8v_hKJqQdvh"
      },
      "source": [
        "Next, let us look at the weights in 'the' main layer. There are actually many layers in BERT. It starts with its own embeddings and goes through various other layers (discussed in detail in next week's live sessions):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4-RDjRUQdvh",
        "outputId": "a1f33fa2-42aa-4882-b50e-bf7eb2a3533b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(bert.layers[0].weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_AA4_mFQdvi"
      },
      "source": [
        "Off.. that's a lot of 'layers'. Let's look at the names and dimensions of the first 11 layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wViSCf-AQdvi",
        "outputId": "e383c46c-fb0f-4f69-8fb5-86baf1258928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Layer name: \t tf_bert_model/bert/embeddings/word_embeddings/weight:0\n",
            "Layer shape: \t (28996, 768)\n",
            "1\n",
            "Layer name: \t tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0\n",
            "Layer shape: \t (2, 768)\n",
            "2\n",
            "Layer name: \t tf_bert_model/bert/embeddings/position_embeddings/embeddings:0\n",
            "Layer shape: \t (512, 768)\n",
            "3\n",
            "Layer name: \t tf_bert_model/bert/embeddings/LayerNorm/gamma:0\n",
            "Layer shape: \t (768,)\n",
            "4\n",
            "Layer name: \t tf_bert_model/bert/embeddings/LayerNorm/beta:0\n",
            "Layer shape: \t (768,)\n",
            "5\n",
            "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0\n",
            "Layer shape: \t (768, 768)\n",
            "6\n",
            "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0\n",
            "Layer shape: \t (768,)\n",
            "7\n",
            "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0\n",
            "Layer shape: \t (768, 768)\n",
            "8\n",
            "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0\n",
            "Layer shape: \t (768,)\n",
            "9\n",
            "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0\n",
            "Layer shape: \t (768, 768)\n",
            "10\n",
            "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0\n",
            "Layer shape: \t (768,)\n"
          ]
        }
      ],
      "source": [
        "for layer in range(11):\n",
        "    print(layer)\n",
        "    print('Layer name: \\t', bert.layers[0].weights[layer].name)\n",
        "    print('Layer shape: \\t', bert.layers[0].weights[layer].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faPBpDmDQdvi"
      },
      "source": [
        "Let's point out a few observations:\n",
        "\n",
        " * We see the embedding layer which maps the token id to a 768 dim vector \n",
        " * Next is the positional encoding which encodes the 512 BERT input positions. looks right.\n",
        " * Layers 5-10 hold the weights and biases for the first self-attention layer\n",
        " \n",
        "So this all seems consistent and as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4SPyDWmQdvj"
      },
      "source": [
        "With the BERT model available, let us create a sample input and then look at the BERT output.\n",
        "\n",
        "BERT has various inputs, but most of them optional (see: https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel). The minimum input are the input ids that should be of shape 'batch size' x 'sequence length'. (Note that in the text further down we will actually construct other inputs as well to be maximally explicit).\n",
        "\n",
        "Here is the proper input of our sample sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7eeQFzFQdvj",
        "outputId": "18d4f4dc-dc39-499f-ce06-4a814c1f10b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 101,  146, 1821, 1304, 2816, 2052,  119,    0,    0,    0,  102]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "input_ids = np.array([tokenizer.encode('I am very happy today. [PAD] [PAD] [PAD]')])\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LvpgPQwQdvj",
        "outputId": "6bb74ad3-7eed-4ca6-f477-440afb52f838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['happy']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens([2816])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRO5HCj0Qdvj",
        "outputId": "363725f6-6fb2-4780-8e34-68721b24694a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnI5HmnjQdvk"
      },
      "source": [
        "That looks right: batch size 1, and length is 13. Now let's look at the bert output for this input. We follow here the Functional API way of thinking as 'output = layer(input)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7LnmXfZQdvk",
        "outputId": "efcdeefe-bac5-45b3-9bd0-2e718ede694e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_output = bert(input_ids)\n",
        "len(bert_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pubpU1oCQdvk"
      },
      "source": [
        "So there are 2 outputs. What are their shapes and interpretation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PlVmg3MQdvk",
        "outputId": "3d0d4fe8-d36c-4663-be06-6360808f59e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 11, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "bert_output[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW9ErU_LQdvl"
      },
      "source": [
        "This first output with dimension 'batch size' x 'length' x 768 are the 768 dimensional **context-based embeddings** of each input token! These are what will replace the traditional word embeddings.\n",
        "\n",
        "Let's look at the output vector for the word happy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59WDib40Qdvl",
        "outputId": "b8f2347d-f59c-41d0-e036-7a977e0bfd5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([ 0.12506893, -0.05962541,  0.06276673, -0.0903696 , -0.11729921,\n",
              "        0.00508308,  0.0964426 , -0.11545924, -0.23156194, -0.02102006,\n",
              "        0.05975346,  0.44875324, -0.06902957,  0.34377098, -0.635573  ,\n",
              "        0.24954206, -0.18619165, -0.28699914,  0.28957322, -0.14723213],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "happy_vec = bert_output[0][0, 4]\n",
        "happy_vec[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4FjBeI3Qdvl"
      },
      "source": [
        "What is the second BERT output?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu54LR2-Qdvl",
        "outputId": "02bc26a2-056b-4afd-ddaf-49febd797dfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "bert_output[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xflTGWd9Qdvl"
      },
      "source": [
        "The second output is the 'pooler output', which is the output of the CLS token, followed by another linear classification with tanh activation.\n",
        "\n",
        "Now, where we understand the tokernizer and the 'black box basics' of BERT, we are ready to work on our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTnjNr3hQdvm"
      },
      "source": [
        "### III.3. Input Generation<a id=\"extract\"/>\n",
        "\n",
        "\n",
        "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
        "\n",
        "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
        "\n",
        "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
        "\n",
        "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
        "\n",
        "4) Create the mask ids. Mask out all of the padding tokens.\n",
        "\n",
        "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
        "\n",
        "To do this, we first define a helper function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "m7ujENujQdvm"
      },
      "outputs": [],
      "source": [
        "def addWord(word, pos, ner):\n",
        "    \"\"\"\n",
        "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
        "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
        "    maintain the 1:1 mappings between word tokens and labels.\n",
        "    \n",
        "    arguments: word, pos label, ner label\n",
        "    returns: dictionary with tokens and labels\n",
        "    \"\"\"\n",
        "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
        "    if word == '\"\"\"\"':\n",
        "        word = '\"'\n",
        "    elif word == '``':\n",
        "        word = '`'\n",
        "        \n",
        "    tokens = tokenizer.tokenize(word)\n",
        "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
        "    \n",
        "    addDict = dict()\n",
        "    \n",
        "    addDict['wordToken'] = tokens\n",
        "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
        "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
        "    addDict['tokenLength'] = tokenLength\n",
        "    \n",
        "    \n",
        "    return addDict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m5-YFHTQdvm"
      },
      "source": [
        "Let's see what it does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GvvnopoQdvn",
        "outputId": "17c15225-b986-4ae2-9b52-3ee032199803"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nerToken': ['O'],\n",
              " 'posToken': ['VB'],\n",
              " 'tokenLength': 1,\n",
              " 'wordToken': ['protest']}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "addWord('protest', 'VB', 'O')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA8u7bi8Qdvn",
        "outputId": "e46b87b3-8ead-45f9-b20c-56e0f26a2fd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nerToken': ['B-geo'],\n",
              " 'posToken': ['NNP'],\n",
              " 'tokenLength': 1,\n",
              " 'wordToken': ['Iraq']}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "addWord('Iraq', 'NNP', 'B-geo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyqmEq42Qdvn",
        "outputId": "611f2913-8c89-47cb-bc6f-4fee93e39490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nerToken': ['O', 'nerX'],\n",
              " 'posToken': ['CD', 'posX'],\n",
              " 'tokenLength': 2,\n",
              " 'wordToken': ['1000', '##0']}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "addWord('10000', 'CD', 'O')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjAVgMecQdvn"
      },
      "source": [
        "We are now ready to convert the text file into appropriate arrays. First, we need to define the length of each example. For this we will define the hyper-parameter max_length. All sentences longer (post-tokenization!) than this parameter will be clipped off, and all sentences that are shorter will be padded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WU8-p_vfQdvo"
      },
      "outputs": [],
      "source": [
        "max_length = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGUzkfdeQdvo"
      },
      "source": [
        "Example creation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "82HtnqKrQdvo"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
        "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
        "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
        "\"\"\"\n",
        "\n",
        "with io.open(data_path + 'ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
        "    text = train.readlines()\n",
        "\n",
        "\n",
        "# lists for sentences, tokens, labels, etc.  \n",
        "sentenceList = []\n",
        "sentenceTokenList = []\n",
        "posTokenList = []\n",
        "nerTokenList = []\n",
        "sentLengthList = []\n",
        "\n",
        "# lists for BERT input\n",
        "bertSentenceIDs = []\n",
        "bertMasks = []\n",
        "bertSequenceIDs = []\n",
        "\n",
        "sentence = ''\n",
        "\n",
        "# always start with [CLS] tokens\n",
        "sentenceTokens = ['[CLS]']\n",
        "posTokens = ['[posCLS]']\n",
        "nerTokens = ['[nerCLS]']\n",
        "\n",
        "for line in text:\n",
        "    \n",
        "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
        "\n",
        "    sent, word, pos, ner = cleanLine.split(',')\n",
        "    \n",
        "    ner = ner[:-1]   # remove DOS token\n",
        "    \n",
        "    # if new sentence starts\n",
        "    if (sent[:8] == 'Sentence'):            \n",
        "            \n",
        "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
        "        sentLengthList.append(sentenceLength)\n",
        "        \n",
        "                    \n",
        "        # Create space for at least a final '[SEP]' token\n",
        "        if sentenceLength >= max_length - 1: \n",
        "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
        "            posTokens = posTokens[:max_length - 2]\n",
        "            nerTokens = nerTokens[:max_length - 2]\n",
        "\n",
        "        # add a ['SEP'] token and padding\n",
        "        \n",
        "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
        "        \n",
        "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
        "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
        "            \n",
        "        sentenceList.append(sentence)\n",
        "\n",
        "        sentenceTokenList.append(sentenceTokens)\n",
        "\n",
        "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
        "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
        "        bertSequenceIDs.append([0] * (max_length))\n",
        "                             \n",
        "        posTokenList.append(posTokens)\n",
        "        nerTokenList.append(nerTokens)\n",
        "        \n",
        "        sentence = ''\n",
        "        sentenceTokens = ['[CLS]']\n",
        "        posTokens = ['[posCLS]']\n",
        "        nerTokens = ['[nerCLS]']\n",
        "        \n",
        "        sentence += ' ' + word\n",
        "\n",
        "    addDict = addWord(word, pos, ner)\n",
        "\n",
        "    sentenceTokens += addDict['wordToken']\n",
        "    posTokens += addDict['posToken']\n",
        "    nerTokens += addDict['nerToken']\n",
        "\n",
        "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
        "sentLengthList = sentLengthList[2:]\n",
        "sentenceTokenList = sentenceTokenList[2:]\n",
        "bertSentenceIDs = bertSentenceIDs[2:]\n",
        "bertMasks = bertMasks[2:]\n",
        "bertSequenceIDs = bertSequenceIDs[2:]\n",
        "posTokenList = posTokenList[2:]\n",
        "nerTokenList = nerTokenList[2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2TrGJXIQdvp"
      },
      "source": [
        "What did this do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcNAM10fQdvp",
        "outputId": "d86c6df3-38ee-4e1d-f6be-f11b0563caf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'They', 'marched', 'from', 'the', 'Houses', 'of', 'Parliament', 'to', 'a', 'rally', 'in', 'Hyde', 'Park', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "print(sentenceTokenList[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2rbY8YRQdvp",
        "outputId": "6d9f62c8-0924-41c8-c04d-44c1a38ad053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
          ]
        }
      ],
      "source": [
        "print(nerTokenList[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjyqwexLQdvq",
        "outputId": "453f5f7f-7a1a-4767-918e-e97f5aea452c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(bertMasks[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkC27_MRQdvq"
      },
      "source": [
        "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pM4vLDtQdvq",
        "outputId": "28306bf1-e9ca-4140-eeaf-e143ec279925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(bertSequenceIDs[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPly4VVkQdvq"
      },
      "source": [
        "Looks reasonable. \n",
        "\n",
        "\n",
        "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
        "\n",
        "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "2DayenSKQdvr",
        "outputId": "b5dcedcf-03fc-4187-f402-33ba68170d46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.0000e+00, 2.0000e+00, 3.0000e+00, 1.9000e+01, 1.0600e+02,\n",
              "        1.8400e+02, 3.0800e+02, 4.3000e+02, 5.1900e+02, 6.6700e+02,\n",
              "        8.2800e+02, 9.4000e+02, 1.0040e+03, 1.1560e+03, 1.2590e+03,\n",
              "        1.3620e+03, 1.4480e+03, 1.5610e+03, 1.5710e+03, 1.7080e+03,\n",
              "        1.7600e+03, 1.8350e+03, 1.9350e+03, 1.9450e+03, 1.9120e+03,\n",
              "        1.8550e+03, 1.9040e+03, 1.9736e+04]),\n",
              " array([ 2.        ,  2.96428571,  3.92857143,  4.89285714,  5.85714286,\n",
              "         6.82142857,  7.78571429,  8.75      ,  9.71428571, 10.67857143,\n",
              "        11.64285714, 12.60714286, 13.57142857, 14.53571429, 15.5       ,\n",
              "        16.46428571, 17.42857143, 18.39285714, 19.35714286, 20.32142857,\n",
              "        21.28571429, 22.25      , 23.21428571, 24.17857143, 25.14285714,\n",
              "        26.10714286, 27.07142857, 28.03571429, 29.        ]),\n",
              " <a list of 28 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sentenceLengths= [l for l in sentLengthList]\n",
        "\n",
        "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg2kpd1SQdvr"
      },
      "source": [
        "An average sentence length of ~25 (incl. extra tokens!) is roughly expected. It turns out that on these types of corpora an average sentence length of ~20 tends to be seen. The big spike on the right obviously corresponds to all sentences that we had to truncate. \n",
        "\n",
        "Next, we analyze the distribution of ner labels. First, we assign numbers to the labels and look at the overall distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aFaRIaNaQdvr"
      },
      "outputs": [],
      "source": [
        "numSentences = len(bertSentenceIDs)\n",
        "\n",
        "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
        "nerClasses.columns = ['tag']\n",
        "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
        "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
        "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
        "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "6AP8XNeDQdvr",
        "outputId": "2f78d66e-d7fb-4ccd-c6f6-4b986c0973f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f859a536f10>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "nerClasses[['cat']].hist(bins=21)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw_8zXiAQdvr"
      },
      "source": [
        "Looks like a lot of tables with value 16+... Let's see which labels these label numbers corresponds to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ff9cIePwQdvs",
        "outputId": "b983079f-bac6-4443-b4d2-47be852bd2cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       tag  cat  occurences\n",
              "0    B-art    0         345\n",
              "1    B-art    1           0\n",
              "2    B-art    2           0\n",
              "3    B-art    3           0\n",
              "4    B-art    4           0\n",
              "..     ...  ...         ...\n",
              "436   nerX   16           0\n",
              "437   nerX   17           0\n",
              "438   nerX   18           0\n",
              "439   nerX   19           0\n",
              "440   nerX   20      166746\n",
              "\n",
              "[441 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b36d9e7-18bb-41fb-b291-6216b7814b10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>cat</th>\n",
              "      <th>occurences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-art</td>\n",
              "      <td>0</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-art</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-art</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-art</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-art</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>nerX</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>nerX</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>nerX</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>nerX</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>nerX</td>\n",
              "      <td>20</td>\n",
              "      <td>166746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b36d9e7-18bb-41fb-b291-6216b7814b10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b36d9e7-18bb-41fb-b291-6216b7814b10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b36d9e7-18bb-41fb-b291-6216b7814b10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
        "                   .rename(columns={'sym':'occurences'}))\n",
        "\n",
        "numNerClasses = nerDistribution.tag.nunique()\n",
        "\n",
        "nerDistribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsmNN0NxQdvs"
      },
      "source": [
        "Interesting. 16 corresponds to 'O', and all 'extension' labels (i.e., those that were not part of the original data) occur at 17+. \n",
        "\n",
        "'O' is the most common token - by far.\n",
        "\n",
        "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
        "\n",
        "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGzCMasDQdvs",
        "outputId": "afed97b5-f6d0-40cd-e900-adc2b5e12a2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8432003701378102"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "O_occurences = int(nerDistribution.loc[nerDistribution.tag == 'O','occurences']\\\n",
        "                                .reset_index().drop(['index'], axis=1).loc[16])   # Some gymnasics to get the count..\n",
        "All_occurences = nerDistribution[nerDistribution.cat < 17]['occurences'].sum()\n",
        "\n",
        "O_occurences/All_occurences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fltQZAZuQdvs"
      },
      "source": [
        "So **84.3%** is the baseline to beat for our first metric! Can we do that? We'll see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j9nL4w7Qdvt"
      },
      "source": [
        "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
        "\n",
        "In the last step we need to prepare both labels and input for the model, including the train/test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OfjhYKG5Qdvt"
      },
      "outputs": [],
      "source": [
        "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyuf9K1CQdvt"
      },
      "source": [
        "We now split - in a pretty manual way - the examples into a train and test set. We create a random binary value for each sentence that we use to split train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "oh78RLriQdvt"
      },
      "outputs": [],
      "source": [
        "numSentences = len(bert_inputs[0])\n",
        "np.random.seed(0)\n",
        "training_examples = np.random.binomial(1, 0.7, numSentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TDwU7-FxQdvt"
      },
      "outputs": [],
      "source": [
        "trainSentence_ids = []\n",
        "trainMasks = []\n",
        "trainSequence_ids = []\n",
        "\n",
        "testSentence_ids = []\n",
        "testMasks = []\n",
        "testSequence_ids = []\n",
        "\n",
        "nerLabels_train =[]\n",
        "nerLabels_test = []\n",
        "\n",
        "\n",
        "for example in range(numSentences):\n",
        "    if training_examples[example] == 1:\n",
        "        trainSentence_ids.append(bert_inputs[0][example])\n",
        "        trainMasks.append(bert_inputs[1][example])\n",
        "        trainSequence_ids.append(bert_inputs[2][example])\n",
        "        nerLabels_train.append(nerLabels[example])\n",
        "    else:\n",
        "        testSentence_ids.append(bert_inputs[0][example])\n",
        "        testMasks.append(bert_inputs[1][example])\n",
        "        testSequence_ids.append(bert_inputs[2][example])\n",
        "        nerLabels_test.append(nerLabels[example])\n",
        "        \n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "nerLabels_train = np.array(nerLabels_train)\n",
        "nerLabels_test = np.array(nerLabels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0FQsbMwQdvu",
        "outputId": "28184ec7-1992-4dda-e545-e7cf433c7e78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
              "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
              "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
              "         102,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "X_train[0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxmvVgzaQdvu",
        "outputId": "8079a2f1-d4e7-4bb3-d543-0b7c67012dc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17, 16, 16, 16, 20, 20, 16, 16, 16,  2, 16, 16, 16, 16, 16,  2, 16,\n",
              "       16, 16, 16, 16,  3, 16, 16, 16, 16, 16, 19, 18, 18], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "nerLabels_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3cQyRZSQdvw",
        "outputId": "0b83d393-04eb-4165-f9d6-b4c998eea7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'Thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.', '[SEP]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "print(sentenceTokenList[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9h-_aMTQdvw"
      },
      "source": [
        "Let's also get a few train/test positions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvU6NZJHQdvw",
        "outputId": "4a936dde-8d9a-42cd-f6b7-140b304ddc1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "training_examples[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELJ9D28DQdvx"
      },
      "source": [
        "In the last step, we prepare the actual train and test input and label data. For convenience (quick functionality test on small data set), we introduce parameters k_start & k_end to just use a slide of the full dataset. (Setting k_end to -1 corresponds to using the whole set (as we will do in the following). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "t0b7AkmLQdvx"
      },
      "outputs": [],
      "source": [
        "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
        "\n",
        "k_start = 0\n",
        "k_end = -1\n",
        "\n",
        "if k_end == -1:\n",
        "    k_end_train = X_train[0].shape[0]\n",
        "    k_end_test = X_test[0].shape[0]\n",
        "else:\n",
        "    k_end_train = k_end_test = k_end\n",
        "    \n",
        "\n",
        "\n",
        "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
        "                       X_train[2][k_start:k_end_train]]\n",
        "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
        "                      X_test[2][k_start:k_end_test]]\n",
        "\n",
        "\n",
        "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
        "labels_test_k = nerLabels_test[k_start:k_end_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "V-oqlN2PQdvx"
      },
      "outputs": [],
      "source": [
        "train_all = [bert_inputs_train_k, labels_train_k]\n",
        "test_all = [bert_inputs_test_k, labels_test_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "BhYxFRt_Qdvy"
      },
      "outputs": [],
      "source": [
        "with open(r\"./bert_train_data.pickle\", \"wb\") as output_file:\n",
        "    pickle.dump(train_all, output_file)\n",
        "    \n",
        "with open(r\"./bert_test_data.pickle\", \"wb\") as output_file:\n",
        "    pickle.dump(test_all, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aFGy5ULGQdvy"
      },
      "outputs": [],
      "source": [
        "with open(r\"./bert_train_data.pickle\", \"rb\") as input_file:\n",
        "    bert_inputs_train_k, labels_train_k = train_all = pickle.load(input_file)\n",
        "    \n",
        "with open(r\"./bert_test_data.pickle\", \"rb\") as input_file:\n",
        "    bert_inputs_test_k, labels_test_k = test_all = pickle.load(input_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "0ryT9TPSQdvy"
      },
      "outputs": [],
      "source": [
        "numNerClasses = 21  # for fast restart w/o the need to recreate data\n",
        "numSentences = 47958\n",
        "\n",
        "#X_train = np.array(train_all[0])\n",
        "#Y_train = np.array(train_all[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCpjXD3cQdvy"
      },
      "source": [
        "That's it. We are all set to go."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jk0dNLGQdvy"
      },
      "source": [
        "## IV. The Model<a id=\"model\"/>\n",
        "\n",
        "### IV.1. Custom Loss & Accuracy<a id=\"custom\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUVVVFXQdvz"
      },
      "source": [
        "We need a **custom loss function** because we only want to optimize for the labels that we actually had in the text, not the extra ones like '[nerPAD]', etc. Our cost function is therefore derived from sparse_categorical_crossentropy, but we choose to modify the function a bit:  we want to mask out all tokens that have a token id larger or equal of 17, corresponding to the extra tokens:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4sJ1BRpqQdvz"
      },
      "outputs": [],
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length + 1) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns:  cost\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
        "    \n",
        "    mask = (y_label < 17)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
        "\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
        "    \n",
        "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
        "    \n",
        "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
        "    \n",
        "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIGRl5BuQdvz"
      },
      "source": [
        "Does it work as advertised? Let's create a toy example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaMYpxBcQdv0",
        "outputId": "a3ea7d98-94be-415e-9a65-1ca0a252bf76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.5108274, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "y_true = tf.constant([[17],[0]])\n",
        "\n",
        "y_pred = tf.constant([\n",
        "    [0.0,0,0,0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
        "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "])\n",
        "\n",
        "\n",
        "# Nice to have eager execution now...\n",
        "\n",
        "print(custom_loss(y_true, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrDLeYr1Qdv0"
      },
      "source": [
        "Compare this to the manual calculation of $-\\log((y^1_{pred})_0)$ (remember that $y^0$ is masked out because the true label is 17) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsAsyZnbQdv1",
        "outputId": "ac87d0ae-ab1f-42ad-d8ce-c95ad1609e65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5108256237659907"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "-np.log(0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlpVcxq7Qdv1"
      },
      "source": [
        "So this is correct! The position where the true label is 17 is ignored because of the mask!\n",
        "\n",
        "In a similar vein, we define and test a **custom accuracy** calculation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "q_o_ZG0fQdv1"
      },
      "outputs": [],
      "source": [
        "def custom_acc_orig_tokens(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss dfunction filtering out also the newly inserted labels\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns: accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    mask = (y_label < 17)\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itNdv8CwQdv1"
      },
      "source": [
        "Let us also define another accuracy calculation that only looks at the non-Other labels: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "v5_25REDQdv1"
      },
      "outputs": [],
      "source": [
        "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns: accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    mask = (y_label < 16)\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmAUVma0Qdv2",
        "outputId": "6d8dc6ed-ba75-4010-fd23-9e95853fdbdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "y_true = tf.constant([[17],[0]])\n",
        "\n",
        "y_pred = tf.constant([\n",
        "    [0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
        "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "])\n",
        "\n",
        "\n",
        "print(custom_acc_orig_tokens(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPiFyrT8Qdv2"
      },
      "source": [
        "Again... correct! The false value for the '17' example is not considered.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZUPVPw4Qdv2"
      },
      "source": [
        "Lastly, define an Adam optimizer with new learning rate and beta parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "vzvrHafKQdv2"
      },
      "outputs": [],
      "source": [
        "adam_customized = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkNbegK2Qdv3"
      },
      "source": [
        "Next, we define the summary statistics for TensorBoard. And then we can construct the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSKx767vQdv3"
      },
      "source": [
        "### IV.2 Model Construction<a id=\"ner_model\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewqDILkkQdv3"
      },
      "source": [
        "Time to build the model! Let's be pretty simple. No drop-out etc for now. But we re-train three BERT layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "9qAP2IKkQdv3"
      },
      "outputs": [],
      "source": [
        "def ner_model(max_input_length, train_layers, optimizer):\n",
        "    \"\"\"\n",
        "    Implementation of NER model\n",
        "    \n",
        "    variables:\n",
        "        max_input_length: number of tokens (max_length + 1)\n",
        "        train_layers: number of layers to be retrained\n",
        "        optimizer: optimizer to be used\n",
        "    \n",
        "    returns: model\n",
        "    \"\"\"\n",
        "    \n",
        "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
        "    \n",
        "    \n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
        "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
        "    \n",
        "    bert_layer = TFBertModel.from_pretrained('bert-base-cased')\n",
        "    \n",
        "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
        "    \n",
        "    if not train_layers == -1:\n",
        "        \n",
        "        retrain_layers = []\n",
        "    \n",
        "        for retrain_layer_number in range(train_layers):\n",
        "\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code)\n",
        "\n",
        "        for w in bert_layer.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                w._trainable = False\n",
        "\n",
        "        # End of freezing section\n",
        "    \n",
        "    bert_sequence = bert_layer(bert_inputs)[0]\n",
        "    \n",
        "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
        "    \n",
        "    pred = tf.keras.layers.Dense(21, activation='softmax', name='ner')(dense)\n",
        "     \n",
        "    print('pred: ', pred)\n",
        "    \n",
        "    ## Prepare for multipe loss functions, although not used here\n",
        "    \n",
        "    losses = {\n",
        "        \"ner\": custom_loss,\n",
        "        }\n",
        "    lossWeights = {\"ner\": 1.0\n",
        "                  }\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "\n",
        "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
        "                                                          custom_acc_orig_non_other_tokens])\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbUR3yLMQdv3"
      },
      "source": [
        "\n",
        "## V. Model Runs/Experiments<a id=\"runs\"/>\n",
        "\n",
        "### V.1. With BERT-Layer Re-Training<a id=\"retrain\"/>\n",
        "\n",
        "It is time to run the first test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSSD5Ik4Qdv4",
        "outputId": "727e440c-2a60-49e4-9843-8856f214d9fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
              "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
              "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
              "         102,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "bert_inputs_train_k[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "4qN49egTQdv4"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyKvBfEyQdv4"
      },
      "source": [
        "Let us choose to retrain the all layers of BERT and then train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnn1VPaLQdv4",
        "outputId": "999f5547-546c-4a12-9aac-b6d115ad5645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " input_masks (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
            "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
            "                                n_state=(None, 30,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30, 256)      196864      ['tf_bert_model[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 30, 256)      0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " ner (Dense)                    (None, 30, 21)       5397        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,512,533\n",
            "Trainable params: 108,512,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "2106/2106 [==============================] - 342s 154ms/step - loss: 0.1364 - custom_acc_orig_tokens: 0.9614 - custom_acc_orig_non_other_tokens: 0.7978 - val_loss: 0.1085 - val_custom_acc_orig_tokens: 0.9676 - val_custom_acc_orig_non_other_tokens: 0.8345\n",
            "Epoch 2/5\n",
            "2106/2106 [==============================] - 321s 153ms/step - loss: 0.1042 - custom_acc_orig_tokens: 0.9686 - custom_acc_orig_non_other_tokens: 0.8340 - val_loss: 0.1044 - val_custom_acc_orig_tokens: 0.9688 - val_custom_acc_orig_non_other_tokens: 0.8406\n",
            "Epoch 3/5\n",
            "2106/2106 [==============================] - 320s 152ms/step - loss: 0.0987 - custom_acc_orig_tokens: 0.9701 - custom_acc_orig_non_other_tokens: 0.8416 - val_loss: 0.1032 - val_custom_acc_orig_tokens: 0.9691 - val_custom_acc_orig_non_other_tokens: 0.8408\n",
            "Epoch 4/5\n",
            "2106/2106 [==============================] - 319s 152ms/step - loss: 0.0959 - custom_acc_orig_tokens: 0.9706 - custom_acc_orig_non_other_tokens: 0.8433 - val_loss: 0.1024 - val_custom_acc_orig_tokens: 0.9694 - val_custom_acc_orig_non_other_tokens: 0.8431\n",
            "Epoch 5/5\n",
            "2106/2106 [==============================] - 319s 151ms/step - loss: 0.0934 - custom_acc_orig_tokens: 0.9713 - custom_acc_orig_non_other_tokens: 0.8475 - val_loss: 0.1021 - val_custom_acc_orig_tokens: 0.9695 - val_custom_acc_orig_non_other_tokens: 0.8439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8597b0b190>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# retrain all layers\n",
        "model = ner_model(max_length + 1, train_layers=-1, optimizer = adam_customized)\n",
        "\n",
        "model.fit(\n",
        "    bert_inputs_train_k, \n",
        "    {\"ner\": labels_train_k },\n",
        "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k }),\n",
        "    epochs=5,\n",
        "    batch_size=16\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p77pjqwVQdv5"
      },
      "source": [
        "**97.0% test accuracy for all original tokens and 84.3% for all original 'non-Other' tokens.... Not bad!!** And some tweaking and tuning should probably increase the values a bit more.\n",
        "\n",
        "Note that we used here the **Adam optimizer with custom values. Did that matter?** Why don't you try it...\n",
        "\n",
        "### V.2. Predictions & Confusion Matrix<a id=\"confusion\" />\n",
        "\n",
        "\n",
        "Let us look and see how well the model performs. We use the test here. (It probably would be better to split the data into train/validation/test, we are somewhat casual here).\n",
        "\n",
        "First, get all of the predictions for the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "NX7SWh0bQdv5"
      },
      "outputs": [],
      "source": [
        "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
        "\n",
        "result = model.predict(\n",
        "    bert_inputs_infer, \n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Sp4u5fQdv5",
        "outputId": "ffef7b23-a33c-4695-9841-7231276f99d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14268, 30, 21)\n"
          ]
        }
      ],
      "source": [
        "print(result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Iefhp99Qdv5"
      },
      "source": [
        "This is the correct shape: # test sentences x sentence length x # classes. \n",
        "Let's get the prediction argmax for a random test sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsf0VixqQdv5",
        "outputId": "a9663326-fcf7-4b8f-9445-fbc723d57bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16  2 16 16 16  6 14 14 14\n",
            " 14 16 16 16 16 16]\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(result, axis=2)[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_N6O62UQdv6"
      },
      "source": [
        "What were the labels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cNPVIY9Qdv6",
        "outputId": "d49855e7-0a1b-44ef-c131-07f3b7b331e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17 16 20 20 16 20 16 16 16 16 16 16 16 16 16 16  2 16 20 16  6 14 20 14\n",
            " 14 16 19 18 18 18]\n"
          ]
        }
      ],
      "source": [
        "print(nerLabels_test[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P07QUE_dQdv6"
      },
      "source": [
        "**Wrong? Correct!** Or.. is it?  \n",
        "\n",
        "**Question: Why are we not bothered by the first and the last 'mistakes', i.e., not identifying 20, 17, 19, 18, etc.?**\n",
        "\n",
        "Let us now get the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "rWpWh4EuQdv6"
      },
      "outputs": [],
      "source": [
        "predictions_flat = [pred for preds in np.argmax(result, axis=2) for pred in preds]\n",
        "labels_flat = [label for labels in nerLabels_test for label in labels]\n",
        "\n",
        "clean_preds = []\n",
        "clean_labels = []\n",
        "\n",
        "for pred, label in zip(predictions_flat, labels_flat):\n",
        "    if label < 17:\n",
        "        clean_preds.append(pred)\n",
        "        clean_labels.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "5KPsf6PqQdv6"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(\n",
        "    clean_labels,\n",
        "    clean_preds,\n",
        "    num_classes=None,\n",
        "    dtype=tf.dtypes.int32,\n",
        "    name=None,\n",
        "    weights=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYcuwm0wQdv7"
      },
      "source": [
        "Probably a little big and unbalanced to display. Let us focus on the rows/columns with the common labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KzxJckOQdv7",
        "outputId": "07addcbf-744b-4e7e-aace-29f46cfc5f59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0,     23,  10452,   4213,      0,   4617,   4901,   5101,\n",
              "            0,      8,   1813,     27,      0,   4002,   5396,   1435,\n",
              "       227722])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "np.sum(cm, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N19vHAtQdv7",
        "outputId": "05fd55f3-38ca-4f82-a697-cf6ac98cbc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  8871     62    262    150     15     36     57    224]\n",
            " [   202   4008     24      4      0      2      1      7]\n",
            " [   741     59   3679    318     12     97    111    356]\n",
            " [   148      5    139   4076      0     38    209    139]\n",
            " [    90      1      6      4   4633      5      6    352]\n",
            " [    85      9     95     74      0   3228    310    318]\n",
            " [     3      1      5    102      0    113   4453     25]\n",
            " [   200     51    316    149    335    241    142 225906]]\n"
          ]
        }
      ],
      "source": [
        "cm_most = np.array(cm)[[2,3,5,6,7,13,14,16],:] [:, [2,3,5,6,7,13,14,16]]\n",
        "\n",
        "print(cm_most)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kfzz-pXzQdv7",
        "outputId": "3212dc16-0bb8-4359-fd27-ac3ba988132c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f84cf75ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(cm_most[:-1,:-1], cmap='Reds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEXb_8KaQdv8"
      },
      "source": [
        "Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hf1nfvsQdv8"
      },
      "source": [
        "### V.3 Without BERT-Layer Retraining (\"Did fine-tuning of BERT layers help?\")\n",
        "\n",
        "We will re-run the model, but without re-training of the top BERT layer: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "3MyzOZUOQdv8"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daJcwoIPQdv8",
        "outputId": "2d49e65f-8b82-4c08-c5dd-d0b9193750f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " input_masks (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
            "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
            "                                n_state=(None, 30,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30, 256)      196864      ['tf_bert_model[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 30, 256)      0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " ner (Dense)                    (None, 30, 21)       5397        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,512,533\n",
            "Trainable params: 108,512,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/8\n",
            "1053/1053 [==============================] - 127s 115ms/step - loss: 0.1938 - custom_acc_orig_tokens: 0.9460 - custom_acc_orig_non_other_tokens: 0.7158 - val_loss: 0.1362 - val_custom_acc_orig_tokens: 0.9599 - val_custom_acc_orig_non_other_tokens: 0.7900\n",
            "Epoch 2/8\n",
            "1053/1053 [==============================] - 118s 112ms/step - loss: 0.1385 - custom_acc_orig_tokens: 0.9587 - custom_acc_orig_non_other_tokens: 0.7813 - val_loss: 0.1260 - val_custom_acc_orig_tokens: 0.9619 - val_custom_acc_orig_non_other_tokens: 0.8040\n",
            "Epoch 3/8\n",
            "1053/1053 [==============================] - 118s 112ms/step - loss: 0.1282 - custom_acc_orig_tokens: 0.9611 - custom_acc_orig_non_other_tokens: 0.7938 - val_loss: 0.1201 - val_custom_acc_orig_tokens: 0.9636 - val_custom_acc_orig_non_other_tokens: 0.8098\n",
            "Epoch 4/8\n",
            "1053/1053 [==============================] - 117s 111ms/step - loss: 0.1213 - custom_acc_orig_tokens: 0.9628 - custom_acc_orig_non_other_tokens: 0.8013 - val_loss: 0.1181 - val_custom_acc_orig_tokens: 0.9638 - val_custom_acc_orig_non_other_tokens: 0.8045\n",
            "Epoch 5/8\n",
            "1053/1053 [==============================] - 117s 111ms/step - loss: 0.1155 - custom_acc_orig_tokens: 0.9641 - custom_acc_orig_non_other_tokens: 0.8084 - val_loss: 0.1161 - val_custom_acc_orig_tokens: 0.9647 - val_custom_acc_orig_non_other_tokens: 0.8130\n",
            "Epoch 6/8\n",
            "1053/1053 [==============================] - 117s 111ms/step - loss: 0.1120 - custom_acc_orig_tokens: 0.9647 - custom_acc_orig_non_other_tokens: 0.8119 - val_loss: 0.1151 - val_custom_acc_orig_tokens: 0.9647 - val_custom_acc_orig_non_other_tokens: 0.8172\n",
            "Epoch 7/8\n",
            "1053/1053 [==============================] - 117s 111ms/step - loss: 0.1090 - custom_acc_orig_tokens: 0.9656 - custom_acc_orig_non_other_tokens: 0.8167 - val_loss: 0.1137 - val_custom_acc_orig_tokens: 0.9654 - val_custom_acc_orig_non_other_tokens: 0.8113\n",
            "Epoch 8/8\n",
            "1053/1053 [==============================] - 117s 111ms/step - loss: 0.1058 - custom_acc_orig_tokens: 0.9664 - custom_acc_orig_non_other_tokens: 0.8206 - val_loss: 0.1150 - val_custom_acc_orig_tokens: 0.9650 - val_custom_acc_orig_non_other_tokens: 0.8196\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8596655f90>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
        "\n",
        "# Instantiate variables\n",
        "\n",
        "model.fit(\n",
        "    bert_inputs_train_k, \n",
        "    {\"ner\": labels_train_k },\n",
        "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
        "    epochs=8,\n",
        "    batch_size=32\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js0EcJJZQdv9"
      },
      "source": [
        "**Somewhat close, but not quite as good.** - While one has to be careful given the different optimizer configurations and number of epochs, it looks as if not re-training BERT - in this case - increased the loss and reduced the accuracy a bit. Let's call this **~96.6%/81.6% accuracy** compared to 97.0%/84.3%. \n",
        "\n",
        "The relative benefit of fine-tuning BERT layers will depend on the problem.\n",
        "\n",
        "**Side Notes:** \n",
        " * Deeper re-training needs more compute resources\n",
        " * Deeper re-training sometimes requires a tuned optimizer\n",
        " * Regularization is definitely important..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9aORUoaQdv9"
      },
      "source": [
        "### V.4. A 90%-Reduced Training Set<a id=\"tiny\"/>\n",
        "\n",
        "\n",
        "The claim is that BERT is also very useful if one doesn't have much data. So let us see what happens if we cut the training data down to 10%. That leaves us with only ~3400 training examples. Not much..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6U7VcbFQdv9",
        "outputId": "bdd5aea1-fe55-402d-ce58-c5ae27d63b64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 33690, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "_pzB21kmQdv9"
      },
      "outputs": [],
      "source": [
        "numTrainSentences = 3370\n",
        "\n",
        "bert_inputs_train_tiny = [bert_inputs_train_k[0][:numTrainSentences,:], \\\n",
        "                          bert_inputs_train_k[1][:numTrainSentences,:], \\\n",
        "                          bert_inputs_train_k[2][:numTrainSentences,:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "c_yk-AH5Qdv-"
      },
      "outputs": [],
      "source": [
        "labels_train_tiny = labels_train_k[:numTrainSentences,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "QrZfDfWyQdv-"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDrXiYtXQdv-"
      },
      "source": [
        "Let us first train without BERT-layer fine-tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIcfrPGBQdv-",
        "outputId": "a91cf6b6-fa99-4bf6-ee25-eb5af258de8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " input_masks (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
            "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
            "                                n_state=(None, 30,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30, 256)      196864      ['tf_bert_model[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 30, 256)      0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " ner (Dense)                    (None, 30, 21)       5397        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,512,533\n",
            "Trainable params: 108,512,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "211/211 [==============================] - 17s 52ms/step - loss: 0.3251 - custom_acc_orig_tokens: 0.9167 - custom_acc_orig_non_other_tokens: 0.5398\n",
            "Epoch 2/5\n",
            "211/211 [==============================] - 11s 53ms/step - loss: 0.1736 - custom_acc_orig_tokens: 0.9497 - custom_acc_orig_non_other_tokens: 0.7237\n",
            "Epoch 3/5\n",
            "211/211 [==============================] - 11s 53ms/step - loss: 0.1537 - custom_acc_orig_tokens: 0.9532 - custom_acc_orig_non_other_tokens: 0.7476\n",
            "Epoch 4/5\n",
            "211/211 [==============================] - 11s 52ms/step - loss: 0.1385 - custom_acc_orig_tokens: 0.9574 - custom_acc_orig_non_other_tokens: 0.7677\n",
            "Epoch 5/5\n",
            "211/211 [==============================] - 11s 51ms/step - loss: 0.1271 - custom_acc_orig_tokens: 0.9602 - custom_acc_orig_non_other_tokens: 0.7828\n",
            "211/211 [==============================] - 53s 254ms/step - loss: 0.1194 - custom_acc_orig_tokens: 0.9623 - custom_acc_orig_non_other_tokens: 0.7965 - val_loss: 0.1676 - val_custom_acc_orig_tokens: 0.9491 - val_custom_acc_orig_non_other_tokens: 0.7181\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84d09d5790>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# retrain all layers\n",
        "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
        "\n",
        "model.fit(\n",
        "    bert_inputs_train_tiny, \n",
        "    {\"ner\": labels_train_tiny },\n",
        "    epochs=5,\n",
        "    batch_size=16\n",
        ")\n",
        "model.fit(\n",
        "    bert_inputs_train_tiny, \n",
        "    {\"ner\": labels_train_tiny },\n",
        "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
        "    epochs=1,\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UX21PQnQdv-"
      },
      "source": [
        "Not too bad, one would think! **~95.3%/74.7%** on the test set, compared to ~96.6%/81.6% accuracy on the full training set (w/o BERT-layer re-training) with 1/10th of the data. So BERT embeddings are serving quite well for a smaller data set. \n",
        "\n",
        "At last, let us also compare this to the case where we retrain all BERT layers. This will shed light on the question whether retraining pays off relatively more when data is scarce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5uCdQRnQdv_",
        "outputId": "c0a1635f-aac9-435b-b2fd-f1ea498bc20b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " input_masks (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
            "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
            "                                n_state=(None, 30,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30, 256)      196864      ['tf_bert_model[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 30, 256)      0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " ner (Dense)                    (None, 30, 21)       5397        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,512,533\n",
            "Trainable params: 108,512,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "211/211 [==============================] - 44s 135ms/step - loss: 1.2449 - custom_acc_orig_tokens: 0.7259 - custom_acc_orig_non_other_tokens: 0.0120\n",
            "Epoch 2/5\n",
            "211/211 [==============================] - 28s 133ms/step - loss: 0.5625 - custom_acc_orig_tokens: 0.8504 - custom_acc_orig_non_other_tokens: 0.0408\n",
            "Epoch 3/5\n",
            "211/211 [==============================] - 28s 131ms/step - loss: 0.4278 - custom_acc_orig_tokens: 0.8776 - custom_acc_orig_non_other_tokens: 0.2303\n",
            "Epoch 4/5\n",
            "211/211 [==============================] - 28s 132ms/step - loss: 0.3523 - custom_acc_orig_tokens: 0.9025 - custom_acc_orig_non_other_tokens: 0.4066\n",
            "Epoch 5/5\n",
            "211/211 [==============================] - 28s 132ms/step - loss: 0.3048 - custom_acc_orig_tokens: 0.9183 - custom_acc_orig_non_other_tokens: 0.5147\n",
            "211/211 [==============================] - 71s 340ms/step - loss: 0.2715 - custom_acc_orig_tokens: 0.9271 - custom_acc_orig_non_other_tokens: 0.5766 - val_loss: 0.2463 - val_custom_acc_orig_tokens: 0.9376 - val_custom_acc_orig_non_other_tokens: 0.6511\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84cc698f10>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# retrain all layers\n",
        "model = ner_model(max_length + 1,train_layers=-1,optimizer=adam_customized)\n",
        "\n",
        "model.fit(\n",
        "    bert_inputs_train_tiny, \n",
        "    {\"ner\": labels_train_tiny },\n",
        "    epochs=5,\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    bert_inputs_train_tiny, \n",
        "    {\"ner\": labels_train_tiny },\n",
        "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
        "    epochs=1,\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6sMRsiQdv_"
      },
      "source": [
        "**96.2%/80.5%** on the reduced set, compared to 97.0%/84.3% test accuracy for all original tokens and for the full dataset (both with layer re-training). That is quite good - only a loss of about 0.8%-points/3.9%-points.\n",
        "\n",
        "Compare that also to the results without layer retraining: ~95.3%/74.7% for the 1/10 data set vs ~96.6%/81.6%  for the full training set, corresponding to a 1.3%-points/6.9%-point reduction.\n",
        "\n",
        "It appears that transfer-learning for small data sets may really benefit from layer re-training. Here is the summary table:\n",
        "\n",
        "\n",
        "|Dataset         | Retrain Layers?           | Base Token Accuracy   | Base Token Accuracy w/o 'Other'   | Notes  |\n",
        "| ------------- |:-------------:| :-------------:| :-------------:|-------------:|\n",
        "| **Full**       | Yes (all) | **97.0%** | **84.3%** |custom Adam, 5 epochs|\n",
        "| **Full**       | No      |   **96.6%** | **81.6%** |default Adam, 8 epochs|\n",
        "| **1/10**  |  Yes (all)      |   **96.2%** | **80.5%** |custom Adam, 6 epochs|\n",
        "| **1/10**  | No     |    **95.3%** | **74.7%**|default Adam, 6 epochs|\n",
        "\n",
        "\n",
        "**Disclaimers/Cautions:**\n",
        "\n",
        "* The models were generally not optimized and/or run for the optimal duration. Numbers of epochs are not consistent and were selected based on 'good-enough for now'-strategy.  Quite possibly some models would benefit from more epochs (and hyper-parameter tuning). \n",
        "\n",
        "* The optimizers (default 'Adam' vs the one with customized values) were varied across model runs, which has a significant impact and results are not directly comparable. (Note: it appears that for the reduced set, the model without layer re-training does not train well on the custom Adam-optimizer, while the one where we re-train all layers does not train with the default values.)\n",
        "\n",
        "Having said this, I do not believe that the findings above would be massively different with a more stringent setup. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP2WRvNbQdv_"
      },
      "source": [
        "## VI. Summary<a id=\"summary\" />\n",
        "\n",
        "This finishes this cursory analysis of \"BERT for NER\". We pre-formatted our dataset, took care of tokenization and new inserted tokens (and labels!), defined a baseline model, and then - it would have been embarassing if we had failed - soundly beat the baseline with our Keras-based BERT+classification model. We saw that retraining of some BERT layers appeared to work well.  \n",
        "We also saw that even a small training set of about 3400 sentences did quite well using this architecture.\n",
        "\n",
        "All in all, we hope that this notebook was useful and despite its length reasonably readable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU7mGaHVQdwA"
      },
      "source": [
        "## Appendix: T5<a id=\"T5\" />\n",
        "\n",
        "\n",
        "Let us now lay the foundations for another useful model: **T5**. \n",
        "\n",
        "T5 is a pre-trained transformer-based text-to-text model introduced by C. Raffel et al in  [\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"](https://arxiv.org/pdf/1910.10683.pdf) , that is also available from Huggingface.  The idea is to view/rephrase tasks as 'text-to-text' problems:   \n",
        "\n",
        "<img src=\"t5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "<center>Image Source: \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"</center>\n",
        "\n",
        "T5 has performed very well on a variety of tasks.\n",
        "\n",
        "In this spirit, let us approach the NER classification discussed above in a completely different may: **as a translation problem**. This may certainly lead to less good results than the BERT model, as phrasing it as a translation problem is not very natural. But it is instructive nevertheless.\n",
        "\n",
        "(**Note:** this is pretty cutting-edge as there is very little information available on fine-tuning of T5 with TensorFlow/Keras. So this notebook should be viewed as work in progress, and mistakes may be present.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exxrv7fhQdwA"
      },
      "source": [
        "T5 is available in various sizes. Here, we use the small size with about 60m parameters.\n",
        "\n",
        "### T5 as a Black Box\n",
        "\n",
        "Let us first play with Huggingface's T5 model. We start with the T5ForConditionalGeneration model imported above to verify some pre-training claims. This model uses a source sentence AND the task as an input and then generates the output token by token.\n",
        "\n",
        "Here are some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307,
          "referenced_widgets": [
            "be72fbb96f5c4fc4815acd4d18271404",
            "0cd6e635f37f4a1e8d6199b76a4d4c97",
            "82e7a2c2a84641f6bdfad3feb0099881",
            "99a26204067e40e484e474d933c8fb89",
            "d134d9b57c214034bd50512de893962b",
            "ac7ab5a8df9a432b93e07ed7598c5560",
            "0843e551ad2f4801a2a0bc6ec6b78977",
            "c2569da3feee4cdbad158131e5407e2d",
            "c8cf9c55a0404546a58b4134a3c26d3a",
            "713fb0fd59524056ae76e5637db29a1b",
            "75d05c1076764a04b7114cca67dad429",
            "bcec8ed69e794e9f9b2072e94c88ff27",
            "c4aaec02a73a4c22a9f0e8c86a06a258",
            "d206759a19e54a46971a43c5e2d0ccb5",
            "450e7776163e4017a132623fcfa42811",
            "7d584ebd8876449f98db38596655f4a7",
            "115e3c777b3e4d30936d0323e6f3705c",
            "d2ce6d474a8b4d2fbcde316d86ecc86c",
            "2c0206fc21664e418081a480e1085c01",
            "52ccc7ff77d54239b161c1db4cbe5303",
            "0e881a782d29461ead5010fe2b96d17c",
            "994f2b1697814130bff428daf56be286",
            "fa893136af0d4379922d8f0a018ec3e9",
            "dbe084b657d84a169c566b543813d3a0",
            "ad97cdd7f3204184a9621e26fea41166",
            "24c8325703d84c98843a684b8dc25484",
            "050716e7a8fb490bbb2f1b5bd0809380",
            "9db1d9ce3c8040da92caeffab70773f4",
            "8fedbe3fa88e47a19a4e6dda80c7605f",
            "fe920a06be0e4444a0e87aebedb581c8",
            "9f5df60dc6a845f29a1aeeb993ce947a",
            "7cc2ea0d4eb64162b298efcd56ef6909",
            "6d0163bc9fca4b3183ebac92895bc23a"
          ]
        },
        "id": "0Wto9M7FQdwA",
        "outputId": "25ab1037-3254-4d03-aa78-100b18e817e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be72fbb96f5c4fc4815acd4d18271404"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcec8ed69e794e9f9b2072e94c88ff27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa893136af0d4379922d8f0a018ec3e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "t5_model = 't5-small'\n",
        "\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
        "t5 = TFT5ForConditionalGeneration.from_pretrained(t5_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx6vHxxiQdwA"
      },
      "source": [
        "Let's test the translation tasks. English to German works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqa_MkP6QdwA",
        "outputId": "285bd137-e9a4-419b-e571-e889e76b15f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
              "array([[13959,  1566,    12,  2968,    10,   149,   508,    19,     8,\n",
              "          629,    58,     1]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "t5_tokenizer('translate English to German: how large is the house?', return_tensors='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpUOdxNQdwB"
      },
      "source": [
        "Spanish is not part of the trained tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mnSSJ_SWQdwB",
        "outputId": "e23d8fa1-02dc-4bf2-cdcc-bc2cd427d41b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> Das Haus ist sehr groß</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "input_ids = t5_tokenizer('translate English to Spanish: the house is very large', return_tensors='tf').input_ids\n",
        "\n",
        "outputs = t5.generate(input_ids)\n",
        "\n",
        "t5_tokenizer.decode(outputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpDpDNmqQdwB"
      },
      "source": [
        "Next, we'll check out the sentiment analysis task. 'sst2 sentence:' is the task instruction, which is then followed by the statement to classify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qe4MmZw6QdwC",
        "outputId": "2eff59d2-7d0d-4149-c96d-d273f9b36af5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> positive</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "input_ids = t5_tokenizer('sst2 sentence: I am so happy today', return_tensors='tf').input_ids\n",
        "outputs = t5.generate(input_ids)\n",
        "t5_tokenizer.decode(outputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ylEF7B5lQdwC",
        "outputId": "f6bb4b86-155d-4e11-af0b-819e7e969464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> negative</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "input_ids = t5_tokenizer('sst2 sentence: I am so sad today', return_tensors='tf').input_ids\n",
        "outputs = t5.generate(input_ids)\n",
        "t5_tokenizer.decode(outputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpaz3QuUQdwC"
      },
      "source": [
        "Looks good!\n",
        "\n",
        "Lastly, here is a summarization example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "XHIBXxcEQdwD"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Hiring picked up last month as states lifted restrictions and stepped up vaccination efforts, \n",
        "with the government reporting on Friday that the American economy added 379,000 jobs last month.\n",
        "The pace of hiring in February was an unexpectedly large improvement over the gains made in January. \n",
        "It was also the strongest showing since October. But there are still about 9.5 million fewer jobs today \\\n",
        "than a year ago. Congress is considering a $1.9 trillion package of pandemic relief intended to carry \\\n",
        "struggling households and businesses through the coming months.\"\"\".replace('\\n', ' ')\n",
        "\n",
        "\n",
        "encoding = t5_tokenizer.encode(\"\"\"summarize: \"\"\" + text, return_tensors='tf')\n",
        "\n",
        "\n",
        "outputs = t5.generate(encoding,\n",
        "                      num_beams=4, \n",
        "                      no_repeat_ngram_size=2,\n",
        "                      min_length=30,\n",
        "                      max_length=100,\n",
        "                      early_stopping=True)\n",
        "\n",
        "summarization = t5_tokenizer.decode(outputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "LIO-vjbzQdwD",
        "outputId": "b6cc29d6-2d84-4bae-8a97-75eb96458d71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> the pace of hiring in February was an unexpectedly large improvement over the gains made in January. but there are still about 9.5 million fewer jobs today than a year ago.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLkU-b3rQdwF"
      },
      "source": [
        "Yes, that's a summary. It feels rather extractive. (The optional 'temperature' argument not used here would have an impact.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2BGHPgwQdwF"
      },
      "source": [
        "**Question:** \n",
        "\n",
        "* *Wait... why do we only give the encoder input? And how is this actually trained? What is the training input?*  \n",
        "\n",
        "We can address these later if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8s8jrmPQdwG"
      },
      "source": [
        "### T5 and our NER problem\n",
        "\n",
        "The basic idea is for us to rephrase NER extraction as a translation problem.\n",
        "\n",
        "So we want to frame a text-to-text task that performs the following 'translation':\n",
        "\n",
        "$$ {\\rm 'London \\ is \\ a \\ great \\ town'} \\ \\rightarrow  {\\rm 'B-loc \\ other \\ other \\ other \\ other'}$$ \n",
        "\n",
        "While it is unusual to view this as a translation problem, it is certainly valid.\n",
        "\n",
        "There are many ways to set up the data and labels. One way is to convert the NER symbols in ways that better map to language: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQHpbd42QdwG",
        "outputId": "f672c6f4-1037-4e54-86fd-3dffb9e662ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-art ['▁begin', '▁cultural'] [1731, 2779]\n",
            "B-eve ['▁begin', '▁event'] [1731, 605]\n",
            "B-geo ['▁begin', '▁location'] [1731, 1128]\n",
            "B-gpe ['▁begin', '▁political'] [1731, 1827]\n",
            "B-nat ['▁begin', '▁natural'] [1731, 793]\n",
            "B-org ['▁begin', '▁organization'] [1731, 1470]\n",
            "B-per ['▁begin', '▁person'] [1731, 568]\n",
            "B-tim ['▁begin', '▁time'] [1731, 97]\n",
            "I-art ['▁continue', '▁cultural'] [916, 2779]\n",
            "I-eve ['▁continue', '▁event'] [916, 605]\n",
            "I-geo ['▁continue', '▁location'] [916, 1128]\n",
            "I-gpe ['▁continue', '▁political'] [916, 1827]\n",
            "I-nat ['▁continue', '▁natural'] [916, 793]\n",
            "I-org ['▁continue', '▁organization'] [916, 1470]\n",
            "I-per ['▁continue', '▁person'] [916, 568]\n",
            "I-tim ['▁continue', '▁time'] [916, 97]\n",
            "O ['▁other'] [119]\n"
          ]
        }
      ],
      "source": [
        "tag_dict = {'B-art':'begin cultural',\n",
        " 'B-eve':'begin event',\n",
        " 'B-geo':'begin location',\n",
        " 'B-gpe':'begin political',\n",
        " 'B-nat':'begin natural',\n",
        " 'B-org':'begin organization',\n",
        " 'B-per':'begin person',\n",
        " 'B-tim':'begin time',\n",
        " 'I-art':'continue cultural',\n",
        " 'I-eve':'continue event',\n",
        " 'I-geo':'continue location',\n",
        " 'I-gpe':'continue political',\n",
        " 'I-nat':'continue natural',\n",
        " 'I-org':'continue organization',\n",
        " 'I-per':'continue person',\n",
        " 'I-tim':'continue time',\n",
        " 'O':'other'}\n",
        "\n",
        "for key, tag in tag_dict.items():\n",
        "    print(key, t5_tokenizer.tokenize(tag), t5_tokenizer.encode(tag)[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nSYdovbQdwG"
      },
      "source": [
        "Next, we specify a maximum input length (we pick 40) and create the training input and labels.\n",
        "\n",
        "Note:\n",
        "\n",
        "* we prepend each sentence with a task description. We use: 'find entities:' . The padded, encoded version of this string consitutes the encoder input. (Note: encoding adds a padding token at the beginning and a <\\/s> token at the end, prior to the padding tokens.)\n",
        "\n",
        "* For the decoder input and the labels we create the suitable NER-token string (with the language-friendly terms). The input starts off with the padding token while the labels end on the sentence-end token <\\/s>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCKZBwl-QdwH",
        "outputId": "08d2c32a-dbbb-44df-992b-96abbd394fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:220: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated\"\n"
          ]
        }
      ],
      "source": [
        "max_len = 40\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "input_sentences = []\n",
        "ner_translations_input = []\n",
        "ner_translations_labels = []\n",
        "\n",
        "input_sentences_t5 = []\n",
        "ner_translations_input_t5 = []\n",
        "ner_translations_labels_t5 = []\n",
        "\n",
        "# define masks for encode4r and decoder\n",
        "enc_in_masks = []\n",
        "dec_in_masks = []\n",
        "\n",
        "###\n",
        "\n",
        "train_input_sentences_t5 = []\n",
        "train_ner_translations_input_t5 = []\n",
        "train_ner_translations_labels_t5 = []\n",
        "\n",
        "train_enc_in_masks_t5 = []\n",
        "train_dec_in_masks_t5 = []\n",
        "\n",
        "###\n",
        "\n",
        "test_input_sentences_t5 = []\n",
        "test_ner_translations_input_t5 = []\n",
        "test_ner_translations_labels_t5 = []\n",
        "\n",
        "test_enc_in_masks_t5 = []\n",
        "test_dec_in_masks_t5 = []\n",
        "\n",
        "###\n",
        "\n",
        "with io.open(data_path + 'ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
        "    text = train.readlines()\n",
        "\n",
        "current_input = 'find entities:'\n",
        "current_translation = '<pad>'\n",
        "current_labels = ''\n",
        "\n",
        "for line_num, line in enumerate(text):\n",
        "    \n",
        "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
        "\n",
        "    sent, word, pos, ner = [x.strip('\\n') for x in cleanLine.split(',')]\n",
        "    #print(word, ner)\n",
        "    word = word.replace('\"\"\"\"', '\"')\n",
        "    word = word.replace('\"\"', '\"')\n",
        "    \n",
        "    if sent.startswith('Sentence:'):\n",
        "        current_input += ' </s>'\n",
        "        current_translation += ' </s>'\n",
        "        current_labels += ' </s>'\n",
        "        \n",
        "        input_sentences.append(current_input)\n",
        "        ner_translations_input.append(current_translation)\n",
        "        ner_translations_labels.append(current_labels)\n",
        "        \n",
        "        \n",
        "        current_input_ids = t5_tokenizer.encode(current_input)\n",
        "        len_input = len(current_input_ids)     \n",
        "        current_input_ids += ([0]* max_len)\n",
        "        current_input_ids = current_input_ids[:max_len]\n",
        "        \n",
        "        enc_in_mask = ([1] * len_input + [0] * max_len)[:max_len]\n",
        "        \n",
        "        current_translation_ids = t5_tokenizer.encode(current_translation)\n",
        "    \n",
        "        dec_in_length = len(current_translation_ids)\n",
        "        current_translation_ids += ([0]* max_len)\n",
        "        current_translation_ids = current_translation_ids[:max_len]\n",
        "        \n",
        "        dec_in_mask = ([1] * dec_in_length + [0] * max_len)[:max_len]\n",
        "        \n",
        "        current_labels_ids = t5_tokenizer.encode(current_labels)\n",
        "        current_labels_ids += ([0]* max_len)\n",
        "        current_labels_ids = current_labels_ids[:max_len]\n",
        "\n",
        "        input_sentences_t5.append(current_input_ids)\n",
        "        ner_translations_input_t5.append(current_translation_ids)\n",
        "        ner_translations_labels_t5.append(current_labels_ids)\n",
        "        \n",
        "        enc_in_masks.append(enc_in_mask)\n",
        "        dec_in_masks.append(dec_in_mask)\n",
        "        \n",
        "        if  np.random.random()< 0.8: \n",
        "            \n",
        "            ## train\n",
        "        \n",
        "            train_input_sentences_t5.append(current_input_ids)\n",
        "            train_ner_translations_input_t5.append(current_translation_ids)\n",
        "            train_ner_translations_labels_t5.append(current_labels_ids)\n",
        "\n",
        "            train_enc_in_masks_t5.append(enc_in_mask)\n",
        "            train_dec_in_masks_t5.append(dec_in_mask)\n",
        "        else:\n",
        "            \n",
        "            ## test\n",
        "\n",
        "            test_input_sentences_t5.append(current_input_ids)\n",
        "            test_ner_translations_input_t5.append(current_translation_ids)\n",
        "            test_ner_translations_labels_t5.append(current_labels_ids)\n",
        "\n",
        "            test_enc_in_masks_t5.append(enc_in_mask)\n",
        "            test_dec_in_masks_t5.append(dec_in_mask)\n",
        "        \n",
        "        current_input = '<pad> ' + 'find entities: ' + word\n",
        "        current_translation = '<pad> ' + tag_dict[ner]\n",
        "        current_labels = ''  + tag_dict[ner]\n",
        "        \n",
        "    \n",
        "    elif sent == '':\n",
        "        current_input += ' ' + word\n",
        "        current_translation += ' ' + tag_dict[ner]\n",
        "        current_labels += ' ' + tag_dict[ner]\n",
        "        \n",
        "    else:\n",
        "        continue\n",
        "        \n",
        "input_sentences = input_sentences[2:]\n",
        "ner_translations_input = ner_translations_input[2:]\n",
        "ner_translations_labels = ner_translations_labels[2:]\n",
        "\n",
        "input_sentences_t5 = np.array(input_sentences_t5[2:])\n",
        "ner_translations_input_t5 = np.array(ner_translations_input_t5[2:])\n",
        "ner_translations_labels_t5 = np.array(ner_translations_labels_t5[2:])\n",
        "enc_in_masks_t5 = np.array(enc_in_masks[2:])\n",
        "dec_in_masks_t5 = np.array(dec_in_masks[2:])\n",
        "\n",
        "train_input_sentences_t5 = np.array(train_input_sentences_t5[2:])\n",
        "train_ner_translations_input_t5 = np.array(train_ner_translations_input_t5[2:])\n",
        "train_ner_translations_labels_t5 = np.array(train_ner_translations_labels_t5[2:])\n",
        "train_enc_in_masks_t5 = np.array(train_enc_in_masks_t5[2:])\n",
        "train_dec_in_masks_t5 = np.array(train_dec_in_masks_t5[2:])\n",
        "\n",
        "test_input_sentences_t5 = np.array(test_input_sentences_t5[2:])\n",
        "test_ner_translations_input_t5 = np.array(test_ner_translations_input_t5[2:])\n",
        "test_ner_translations_labels_t5 = np.array(test_ner_translations_labels_t5[2:])\n",
        "test_enc_in_masks_t5 = np.array(test_enc_in_masks_t5[2:])\n",
        "test_dec_in_masks_t5 = np.array(test_dec_in_masks_t5[2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZvLcsAHQdwH",
        "outputId": "174488a0-0ab8-4237-8b16-2ac48b96a972"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38312"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "len(train_dec_in_masks_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82g8uritQdwH"
      },
      "source": [
        "Here are examples of input sentence, decoder input string, and labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "72QkdPtwQdwI",
        "outputId": "6104c99b-cb57-41b2-f739-13bf4d7c5e4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> find entities: They marched from the Houses of Parliament to a rally in Hyde Park . </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "input_sentences[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QLgi8pFOQdwI",
        "outputId": "9b936935-ebd4-4848-e296-08676e461f06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> other other other other other other other other other other other begin location continue location other </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "ner_translations_input[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_sf2SQdxQdwI",
        "outputId": "e2dc8493-98e9-4a21-c290-5297ae6105e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other other other other other other other other other other other begin location continue location other </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "ner_translations_labels[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKrcG--QdwJ"
      },
      "source": [
        "Let's also check the corresponding encoder and decoder input masks that are supposed to mask outpad tokens: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6FYqLaGQdwJ",
        "outputId": "46601ea8-1ed3-40f1-caf3-7a6cb5fd746a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "enc_in_masks_t5[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKlVck_OQdwJ",
        "outputId": "0c3e2e3e-4ea2-4779-f6cf-191fbc92ac55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:220: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "np.sum(enc_in_masks_t5[1]) == len(t5_tokenizer.encode(input_sentences[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FMm1Tt5QdwJ",
        "outputId": "e7f75273-e32f-49c9-c6c4-63bc129496fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "dec_in_masks_t5[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJFnu9_6QdwK",
        "outputId": "56c778c5-aedf-47dd-aaa8-d8e01ac4a2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:220: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "np.sum(dec_in_masks_t5[1]) == len(t5_tokenizer.encode(ner_translations_input[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3zpM1GFQdwK"
      },
      "source": [
        "Looks good. Masks have the right lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhOCJe8PQdwK"
      },
      "source": [
        "Just like before in the BERT architecture we define custom accuracies and custom loss functions:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "gKSmiGVJQdwK"
      },
      "outputs": [],
      "source": [
        "def t5_custom_acc_orig_tokens(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    accuracy across all non-padding/non-eos tokens. \n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    numNerClasses = y_pred.shape[-1]\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    mask =  (y_label > 1)\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "XOh9jwCoQdwL"
      },
      "outputs": [],
      "source": [
        "def t5_custom_acc_orig_tokens_no_other(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    accuracy across all non-padding/non-eos tokens except for 'other'-token.\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    numNerClasses = y_pred.shape[-1]\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    mask_119 =  (y_label != 119)\n",
        "    #print('mask_119', mask_119)\n",
        "    mask_0 =  (y_label > 1)\n",
        "    #print('mask_0', mask_0)\n",
        "    mask =  tf.math.logical_and(mask_119, mask_0)\n",
        "    #print('mask', mask)\n",
        "    \n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "QVAiTYj6QdwL"
      },
      "outputs": [],
      "source": [
        "def t5_custom_acc_orig_tokens_begin_cont(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    accuracty for 'begin'- and 'continue'-tokens\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    numNerClasses = y_pred.shape[-1]\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    \n",
        "    \n",
        "    mask_916 =  (y_label == 916)\n",
        "    mask_1731 =  (y_label == 1731)\n",
        "    \n",
        "    begin_cont_mask = tf.math.logical_or(mask_916, mask_1731)\n",
        "    \n",
        "    #print('mask_119', mask_119)\n",
        "    mask_0 =  (y_label > 1)\n",
        "    #print('mask_0', mask_0)\n",
        "    mask =  tf.math.logical_and(begin_cont_mask, mask_0)\n",
        "    #print('mask', mask)\n",
        "    \n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "jchsFIlRQdwT"
      },
      "outputs": [],
      "source": [
        "def t5_custom_acc_orig_tokens_not_begin_cont_other(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    accuracy for the actual non-'other' tokens, excluding also 'begin'- and 'continue'-tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    numNerClasses = y_pred.shape[-1]\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    \n",
        "    \n",
        "    mask_916 =  (y_label != 916)\n",
        "    mask_1731 =  (y_label != 1731)\n",
        "    mask_119 =  (y_label != 119)\n",
        "    \n",
        "    not_begin_cont_other_mask = tf.math.logical_and(tf.math.logical_and(mask_916, mask_1731), mask_119)\n",
        "    \n",
        "    #print('mask_119', mask_119)\n",
        "    mask_0 =  (y_label > 1)\n",
        "    #print('mask_0', mask_0)\n",
        "    mask =  tf.math.logical_and(not_begin_cont_other_mask, mask_0)\n",
        "    #print('mask', mask)\n",
        "    \n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pocwi1mQdwT"
      },
      "source": [
        "Let's do a few tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA390wK7QdwU",
        "outputId": "0ea9d7dd-ccb7-4417-fdca-9a83cea98c05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=1.0>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "y_pred = tf.constant([[[0.5,0.2,0.3, 0.0], [0.1,0.7,0.2, 0.0], [0.1,0.3,0.6, 0.0], [0.1,0.3,0.0, 0.6]]])\n",
        "y_true = tf.constant([[1], [0], [2], [3]])\n",
        "\n",
        "t5_custom_acc_orig_tokens_no_other(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaDt-XSzQdwU"
      },
      "source": [
        "And again, let's define a custom loss function that removes padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "_xTG9DkYQdwU"
      },
      "outputs": [],
      "source": [
        "def t5_custom_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length + 1) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns:  cost\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    numNerClasses = y_pred.shape[-1]\n",
        "    \n",
        "    #print('numNerClasses', numNerClasses)\n",
        "    \n",
        "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
        "    \n",
        "    mask = (y_label > 1)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
        "\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
        "    \n",
        "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
        "    \n",
        "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
        "    \n",
        "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=True ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXltt5_UQdwU"
      },
      "source": [
        "Our model consists of 3 inputs:\n",
        "\n",
        "* the input ids \n",
        "* the masks to mask out padding in the encoder\n",
        "* the decoder ids from the NER string\n",
        "\n",
        "We then use the **TFT5ForConditionalGeneration** model to implement our task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "yxiLiFHkQdwV"
      },
      "outputs": [],
      "source": [
        "def t5_keras_model():\n",
        "    \n",
        "    \n",
        "    encode_in = tf.keras.layers.Input(shape=(max_len,), dtype='int32', name=\"encode_in_ids\")\n",
        "    enc_mask_in = tf.keras.layers.Input(shape=(max_len,), dtype='int32', name=\"enc_mask_in_ids\")\n",
        "    decode_in = tf.keras.layers.Input(shape=(None,), dtype='int32', name=\"decode_in_ids\")\n",
        "    dec_mask_in = tf.keras.layers.Input(shape=(None,), dtype='int32', name=\"dec_mask_in_ids\")\n",
        "    \n",
        "    t5_layer = TFT5ForConditionalGeneration.from_pretrained(t5_model)\n",
        "    \n",
        "    t5_out = t5_layer({'input_ids': encode_in, \n",
        "                       'decoder_input_ids':decode_in, \n",
        "                       'attention_mask':enc_mask_in,\n",
        "                       'decoder_attention_mask':dec_mask_in\n",
        "                      }, \n",
        "                             return_dict=True)\n",
        "    \n",
        "    pred_logits = t5_out['logits']\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=[encode_in, \n",
        "                                          enc_mask_in, \n",
        "                                          decode_in,\n",
        "                                          dec_mask_in\n",
        "                                         ], \n",
        "                                  outputs=pred_logits)\n",
        "\n",
        "    model.compile(loss=t5_custom_loss, \n",
        "                  optimizer=tf.keras.optimizers.Adam(), \n",
        "                  metrics=[\n",
        "                  #     tf.keras.metrics.Accuracy(),\n",
        "                          t5_custom_acc_orig_tokens, \n",
        "                           t5_custom_acc_orig_tokens_no_other,\n",
        "                      t5_custom_acc_orig_tokens_begin_cont,\n",
        "                      t5_custom_acc_orig_tokens_not_begin_cont_other\n",
        "                  #\n",
        "                  ]\n",
        "                 )\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI0aGH_hQdwV",
        "outputId": "051aee1c-c466-41f0-abb8-16c3cb53ee99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " enc_mask_in_ids (InputLayer)   [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " dec_mask_in_ids (InputLayer)   [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decode_in_ids (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encode_in_ids (InputLayer)     [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " tft5_for_conditional_generatio  TFSeq2SeqLMOutput(l  60506624   ['enc_mask_in_ids[0][0]',        \n",
            " n (TFT5ForConditionalGeneratio  oss=None, logits=(N              'dec_mask_in_ids[0][0]',        \n",
            " n)                             one, None, 32128),                'decode_in_ids[0][0]',          \n",
            "                                 past_key_values=((               'encode_in_ids[0][0]']          \n",
            "                                (None, 8, None, 64)                                               \n",
            "                                , (None, 8, None, 6                                               \n",
            "                                4),                                                               \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                )),                                                               \n",
            "                                 ((None, 8, None, 6                                               \n",
            "                                4),                                                               \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                )),                                                               \n",
            "                                 ((None, 8, None, 6                                               \n",
            "                                4),                                                               \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                )),                                                               \n",
            "                                 ((None, 8, None, 6                                               \n",
            "                                4),                                                               \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                )),                                                               \n",
            "                                 ((None, 8, None, 6                                               \n",
            "                                4),                                                               \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                )),                                                               \n",
            "                                 ((None, 8, None, 6                                               \n",
            "                                4),                                                               \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 8, None, 64                                               \n",
            "                                ))),                                                              \n",
            "                                 decoder_hidden_sta                                               \n",
            "                                tes=None, decoder_a                                               \n",
            "                                ttentions=None, cro                                               \n",
            "                                ss_attentions=None,                                               \n",
            "                                 encoder_last_hidde                                               \n",
            "                                n_state=(None, 40,                                                \n",
            "                                512),                                                             \n",
            "                                 encoder_hidden_sta                                               \n",
            "                                tes=None, encoder_a                                               \n",
            "                                ttentions=None)                                                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 60,506,624\n",
            "Trainable params: 60,506,624\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "try:\n",
        "    del t5_ner_model\n",
        "except:\n",
        "    pass\n",
        "\n",
        "t5_ner_model = t5_keras_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUKkW8l_QdwW"
      },
      "source": [
        "Indeed, we have about 60m parameters.\n",
        "\n",
        "We now use Keras to fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKqPyxFxQdwW",
        "outputId": "bd2ee2cb-db5f-43c9-ce3b-21753313662b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "4789/4789 [==============================] - 385s 78ms/step - loss: 0.2028 - t5_custom_acc_orig_tokens: 0.9263 - t5_custom_acc_orig_tokens_no_other: 0.7856 - t5_custom_acc_orig_tokens_begin_cont: 0.7035 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.8680 - val_loss: 0.1071 - val_t5_custom_acc_orig_tokens: 0.9625 - val_t5_custom_acc_orig_tokens_no_other: 0.8878 - val_t5_custom_acc_orig_tokens_begin_cont: 0.8592 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9166\n",
            "Epoch 2/6\n",
            "4789/4789 [==============================] - 371s 77ms/step - loss: 0.1079 - t5_custom_acc_orig_tokens: 0.9609 - t5_custom_acc_orig_tokens_no_other: 0.8886 - t5_custom_acc_orig_tokens_begin_cont: 0.8614 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9158 - val_loss: 0.0890 - val_t5_custom_acc_orig_tokens: 0.9684 - val_t5_custom_acc_orig_tokens_no_other: 0.8934 - val_t5_custom_acc_orig_tokens_begin_cont: 0.8675 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9194\n",
            "Epoch 3/6\n",
            "4789/4789 [==============================] - 369s 77ms/step - loss: 0.0901 - t5_custom_acc_orig_tokens: 0.9678 - t5_custom_acc_orig_tokens_no_other: 0.9070 - t5_custom_acc_orig_tokens_begin_cont: 0.8887 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9253 - val_loss: 0.0821 - val_t5_custom_acc_orig_tokens: 0.9721 - val_t5_custom_acc_orig_tokens_no_other: 0.9136 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9020 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9252\n",
            "Epoch 4/6\n",
            "4789/4789 [==============================] - 368s 77ms/step - loss: 0.0795 - t5_custom_acc_orig_tokens: 0.9714 - t5_custom_acc_orig_tokens_no_other: 0.9165 - t5_custom_acc_orig_tokens_begin_cont: 0.9026 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9305 - val_loss: 0.0806 - val_t5_custom_acc_orig_tokens: 0.9722 - val_t5_custom_acc_orig_tokens_no_other: 0.9176 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9109 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9243\n",
            "Epoch 5/6\n",
            "4789/4789 [==============================] - 369s 77ms/step - loss: 0.0730 - t5_custom_acc_orig_tokens: 0.9737 - t5_custom_acc_orig_tokens_no_other: 0.9223 - t5_custom_acc_orig_tokens_begin_cont: 0.9101 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9347 - val_loss: 0.0855 - val_t5_custom_acc_orig_tokens: 0.9695 - val_t5_custom_acc_orig_tokens_no_other: 0.9254 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9237 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9272\n",
            "Epoch 6/6\n",
            "4789/4789 [==============================] - 368s 77ms/step - loss: 0.0674 - t5_custom_acc_orig_tokens: 0.9756 - t5_custom_acc_orig_tokens_no_other: 0.9277 - t5_custom_acc_orig_tokens_begin_cont: 0.9161 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9394 - val_loss: 0.0807 - val_t5_custom_acc_orig_tokens: 0.9732 - val_t5_custom_acc_orig_tokens_no_other: 0.9216 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9154 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f83c7c348d0>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "cut_off = 20000000\n",
        "\n",
        "t5_ner_model.fit([train_input_sentences_t5[:cut_off], \n",
        "                      train_enc_in_masks_t5[:cut_off], \n",
        "                      train_ner_translations_input_t5[:cut_off],\n",
        "                      train_dec_in_masks_t5[:cut_off]\n",
        "                     ],\n",
        "                   train_ner_translations_labels_t5[:cut_off],\n",
        "                 validation_data=([test_input_sentences_t5[:cut_off],\n",
        "                                   test_enc_in_masks_t5[:cut_off], \n",
        "                                   test_ner_translations_input_t5[:cut_off],\n",
        "                                   test_dec_in_masks_t5[:cut_off]],\n",
        "                                test_ner_translations_labels_t5[:cut_off]),\n",
        "                 batch_size=8,\n",
        "                epochs=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7CJFbkAQdwW"
      },
      "source": [
        "Looks great! It learned, and the test accuracies are well into the 90% range!  But be careful... the metrics above have been achieved with **teacher-forcing**. In actual inference mode where you do not force the correct input at each decoder time-step, but instead generate the the NER-token step by step, any error will affect the next prediction. This will likely increase the error rate noticeably.\n",
        "\n",
        "**Question for the Reader:** *can you write code that calculates actual accuracies, i.e., generates the NER tokens token-by-token in inference mode?*\n",
        "\n",
        "\n",
        "For now, we leave it as an exercise to the reader to write the corresponding inference loop (using past key values, etc.) and to compare the results using T5 with the those of the BERT model quoted earlier in this paper. \n",
        "\n",
        "But either way, the main point is established: the architecture learns reasonably well and the results are far from random. And most importantly, we hope that these steps help you to **get started with T5.** "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "BERT_T5_NER_2_3_030521.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "764c218231324ecfa94677e392a9411a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59b7629edba64b03bd56b8c913d69939",
              "IPY_MODEL_a5c46d2313ce4e1398bb63987ec825fb",
              "IPY_MODEL_d1c0db0deccc4aa49bfea48ddbc4d894"
            ],
            "layout": "IPY_MODEL_631572ea28524a7fad5de795081a83a9"
          }
        },
        "59b7629edba64b03bd56b8c913d69939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_877841b5b2a74a20851dff467b273a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_19f7165ed7cb4f32a2fa179f838603a5",
            "value": "Downloading: 100%"
          }
        },
        "a5c46d2313ce4e1398bb63987ec825fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5302e1f680d4681922dcf1450da0c88",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fee95b7865144a5815e1cab1fb5d78e",
            "value": 213450
          }
        },
        "d1c0db0deccc4aa49bfea48ddbc4d894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71090841b24a4007ba20b9c3c3445970",
            "placeholder": "​",
            "style": "IPY_MODEL_6feb9d69a6d542dca9aa4abd48fcfe0e",
            "value": " 208k/208k [00:00&lt;00:00, 2.14MB/s]"
          }
        },
        "631572ea28524a7fad5de795081a83a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877841b5b2a74a20851dff467b273a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f7165ed7cb4f32a2fa179f838603a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5302e1f680d4681922dcf1450da0c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fee95b7865144a5815e1cab1fb5d78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71090841b24a4007ba20b9c3c3445970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6feb9d69a6d542dca9aa4abd48fcfe0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a9d59aa6ae4958a190214ff60b851d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64f16e2323214a6099a29651939c9a3f",
              "IPY_MODEL_321cbfaf8f1a47e99f2f3809f17221b0",
              "IPY_MODEL_c1d63282168a4319973e7ede17650700"
            ],
            "layout": "IPY_MODEL_e91ca6e9c9d8491b8365660ca4ff1b05"
          }
        },
        "64f16e2323214a6099a29651939c9a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1073082c5b3447d7b748cbc11e913b64",
            "placeholder": "​",
            "style": "IPY_MODEL_fca76ca76f40487bbceb0e0e390a7a46",
            "value": "Downloading: 100%"
          }
        },
        "321cbfaf8f1a47e99f2f3809f17221b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c939112d05f459fac9f37dd4977457b",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3930e1bc6a14c989c0be7d38944331b",
            "value": 29
          }
        },
        "c1d63282168a4319973e7ede17650700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680b36070820443487c5eb089634ab80",
            "placeholder": "​",
            "style": "IPY_MODEL_990fcbeaf5654eaf991c6371ec55b9bf",
            "value": " 29.0/29.0 [00:00&lt;00:00, 916B/s]"
          }
        },
        "e91ca6e9c9d8491b8365660ca4ff1b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1073082c5b3447d7b748cbc11e913b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca76ca76f40487bbceb0e0e390a7a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c939112d05f459fac9f37dd4977457b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3930e1bc6a14c989c0be7d38944331b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "680b36070820443487c5eb089634ab80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990fcbeaf5654eaf991c6371ec55b9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b46891c58a684293b13a71beb1e709dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87efb493cfe434da681ad61ae0f5ed4",
              "IPY_MODEL_6c9a630a1ed14b0cb4a4ca3de1216b34",
              "IPY_MODEL_7435b402084042d395611ca4e70326e3"
            ],
            "layout": "IPY_MODEL_806be634a1e84792915986f8bda67b62"
          }
        },
        "d87efb493cfe434da681ad61ae0f5ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c6f0f87dcc403588ad5c2d86cf4937",
            "placeholder": "​",
            "style": "IPY_MODEL_1fde0878b74b421ca5090b76adc4aa83",
            "value": "Downloading: 100%"
          }
        },
        "6c9a630a1ed14b0cb4a4ca3de1216b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12cd825ea3fc460796e7c8c05c85a1de",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b8a4875b6004b1bafc68826b62075c0",
            "value": 570
          }
        },
        "7435b402084042d395611ca4e70326e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2557e751034ee49a5d53f6ea635348",
            "placeholder": "​",
            "style": "IPY_MODEL_11714a114f5b49e2a01e2c03c081510f",
            "value": " 570/570 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "806be634a1e84792915986f8bda67b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c6f0f87dcc403588ad5c2d86cf4937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fde0878b74b421ca5090b76adc4aa83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12cd825ea3fc460796e7c8c05c85a1de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8a4875b6004b1bafc68826b62075c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d2557e751034ee49a5d53f6ea635348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11714a114f5b49e2a01e2c03c081510f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "563cd6e39b654075ae9ebd8924071786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09ca6b2f20e2434bb984b1231e229d3d",
              "IPY_MODEL_2510857b66f0425ba78b8e4574b1f841",
              "IPY_MODEL_615271962cbf4f979a4226647b5d5e9f"
            ],
            "layout": "IPY_MODEL_d560949597b54eaca5ccf54ef1471994"
          }
        },
        "09ca6b2f20e2434bb984b1231e229d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf81c6d89e004f4da12b23c52ad2c2be",
            "placeholder": "​",
            "style": "IPY_MODEL_78426cfe20e24df288bed67ad48e14a5",
            "value": "Downloading: 100%"
          }
        },
        "2510857b66f0425ba78b8e4574b1f841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a80d84aa694ce28510254bdc2288b0",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de58e65b6e704c6abd5461914b4036af",
            "value": 526681800
          }
        },
        "615271962cbf4f979a4226647b5d5e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841daef38713493ba32fb0aa312832c3",
            "placeholder": "​",
            "style": "IPY_MODEL_525e38dce0c44433b01df3a9e1da922d",
            "value": " 502M/502M [00:08&lt;00:00, 60.7MB/s]"
          }
        },
        "d560949597b54eaca5ccf54ef1471994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf81c6d89e004f4da12b23c52ad2c2be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78426cfe20e24df288bed67ad48e14a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7a80d84aa694ce28510254bdc2288b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de58e65b6e704c6abd5461914b4036af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "841daef38713493ba32fb0aa312832c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525e38dce0c44433b01df3a9e1da922d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be72fbb96f5c4fc4815acd4d18271404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cd6e635f37f4a1e8d6199b76a4d4c97",
              "IPY_MODEL_82e7a2c2a84641f6bdfad3feb0099881",
              "IPY_MODEL_99a26204067e40e484e474d933c8fb89"
            ],
            "layout": "IPY_MODEL_d134d9b57c214034bd50512de893962b"
          }
        },
        "0cd6e635f37f4a1e8d6199b76a4d4c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7ab5a8df9a432b93e07ed7598c5560",
            "placeholder": "​",
            "style": "IPY_MODEL_0843e551ad2f4801a2a0bc6ec6b78977",
            "value": "Downloading: 100%"
          }
        },
        "82e7a2c2a84641f6bdfad3feb0099881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2569da3feee4cdbad158131e5407e2d",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8cf9c55a0404546a58b4134a3c26d3a",
            "value": 791656
          }
        },
        "99a26204067e40e484e474d933c8fb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_713fb0fd59524056ae76e5637db29a1b",
            "placeholder": "​",
            "style": "IPY_MODEL_75d05c1076764a04b7114cca67dad429",
            "value": " 773k/773k [00:00&lt;00:00, 1.66MB/s]"
          }
        },
        "d134d9b57c214034bd50512de893962b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7ab5a8df9a432b93e07ed7598c5560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0843e551ad2f4801a2a0bc6ec6b78977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2569da3feee4cdbad158131e5407e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cf9c55a0404546a58b4134a3c26d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "713fb0fd59524056ae76e5637db29a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d05c1076764a04b7114cca67dad429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcec8ed69e794e9f9b2072e94c88ff27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4aaec02a73a4c22a9f0e8c86a06a258",
              "IPY_MODEL_d206759a19e54a46971a43c5e2d0ccb5",
              "IPY_MODEL_450e7776163e4017a132623fcfa42811"
            ],
            "layout": "IPY_MODEL_7d584ebd8876449f98db38596655f4a7"
          }
        },
        "c4aaec02a73a4c22a9f0e8c86a06a258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_115e3c777b3e4d30936d0323e6f3705c",
            "placeholder": "​",
            "style": "IPY_MODEL_d2ce6d474a8b4d2fbcde316d86ecc86c",
            "value": "Downloading: 100%"
          }
        },
        "d206759a19e54a46971a43c5e2d0ccb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c0206fc21664e418081a480e1085c01",
            "max": 1197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52ccc7ff77d54239b161c1db4cbe5303",
            "value": 1197
          }
        },
        "450e7776163e4017a132623fcfa42811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e881a782d29461ead5010fe2b96d17c",
            "placeholder": "​",
            "style": "IPY_MODEL_994f2b1697814130bff428daf56be286",
            "value": " 1.17k/1.17k [00:00&lt;00:00, 39.0kB/s]"
          }
        },
        "7d584ebd8876449f98db38596655f4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "115e3c777b3e4d30936d0323e6f3705c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ce6d474a8b4d2fbcde316d86ecc86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c0206fc21664e418081a480e1085c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ccc7ff77d54239b161c1db4cbe5303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e881a782d29461ead5010fe2b96d17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "994f2b1697814130bff428daf56be286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa893136af0d4379922d8f0a018ec3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbe084b657d84a169c566b543813d3a0",
              "IPY_MODEL_ad97cdd7f3204184a9621e26fea41166",
              "IPY_MODEL_24c8325703d84c98843a684b8dc25484"
            ],
            "layout": "IPY_MODEL_050716e7a8fb490bbb2f1b5bd0809380"
          }
        },
        "dbe084b657d84a169c566b543813d3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db1d9ce3c8040da92caeffab70773f4",
            "placeholder": "​",
            "style": "IPY_MODEL_8fedbe3fa88e47a19a4e6dda80c7605f",
            "value": "Downloading: 100%"
          }
        },
        "ad97cdd7f3204184a9621e26fea41166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe920a06be0e4444a0e87aebedb581c8",
            "max": 242303832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f5df60dc6a845f29a1aeeb993ce947a",
            "value": 242303832
          }
        },
        "24c8325703d84c98843a684b8dc25484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc2ea0d4eb64162b298efcd56ef6909",
            "placeholder": "​",
            "style": "IPY_MODEL_6d0163bc9fca4b3183ebac92895bc23a",
            "value": " 231M/231M [00:04&lt;00:00, 61.0MB/s]"
          }
        },
        "050716e7a8fb490bbb2f1b5bd0809380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db1d9ce3c8040da92caeffab70773f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fedbe3fa88e47a19a4e6dda80c7605f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe920a06be0e4444a0e87aebedb581c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5df60dc6a845f29a1aeeb993ce947a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cc2ea0d4eb64162b298efcd56ef6909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0163bc9fca4b3183ebac92895bc23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}